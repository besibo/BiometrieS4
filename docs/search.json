[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "TP de Biométrie Semestre 4",
    "section": "",
    "text": "Introduction"
  },
  {
    "objectID": "index.html#objectifs",
    "href": "index.html#objectifs",
    "title": "TP de Biométrie Semestre 4",
    "section": "Objectifs",
    "text": "Objectifs\nCe livre contient l’ensemble du matériel (contenus, exemples, exercices…) nécessaire à la réalisation des travaux pratiques sous R pour la Biométrie de l’EC ‘Outils pour l’étude et la compréhension du vivant 3’ du semestre 4 de la licence Sciences de la Vie de La Rochelle Université.\nÀ l’issue des 3 séances prévues ce semestre (2 TP et 1 TEA), vous devriez être capables de faire les choses suivantes dans le logiciel RStudio :\n\nExplorer des jeux de données en produisant des résumés statistiques de variables de différentes natures (numériques continues ou catégorielles) et en produisant des graphiques appropriés.\nÊtre capables de distinguer les notions de dispersion et d’incertitude.\nCalculer des statistiques descriptives permettant de déterminer la position (moyennes, médianes, quartiles…) et la dispersion des données (écart-types, variances, intervalles inter-quartiles…) pour plusieurs sous-groupes de vos jeux de données, et les représenter sur des graphiques adaptés.\nCalculer des indices d’incertitude (erreurs standard, intervalles de confiance…) pour plusieurs sous-groupes de vos jeux de données, et les représenter sur des graphiques adaptés."
  },
  {
    "objectID": "index.html#sec-prerequis",
    "href": "index.html#sec-prerequis",
    "title": "TP de Biométrie Semestre 4",
    "section": "Pré-requis",
    "text": "Pré-requis\nPour atteindre les objectifs fixés ici, et compte tenu du volume horaire restreint qui est consacré aux TP et TEA de Biométrie au S4, vous devez obligatoirement posséder un certain nombre de pré-requis. En particulier, vous devriez avoir à ce stade une bonne connaissance de l’interface des logiciels R et RStudio, et vous devriez être capables :\n\nde créer un Rproject et un script d’analyse dans RStudio\nd’importer des jeux de données issus de tableurs dans RStudio\nd’effectuer des manipulations de données simples (sélectionner des variables, trier des colonnes, filtrer des lignes, créer de nouvelles variables, etc.)\nde produire des graphiques de qualité, adaptés à la fois aux variables dont vous disposez et aux questions auxquelles vous souhaitez répondre.\n\n\n\n\n\n\n\nSi ces pré-requis ne sont pas maîtrisés\n\n\n\nMettez-vous à niveau de toute urgence en lisant attentivement le livre en ligne de Biométrie du semestre 3"
  },
  {
    "objectID": "index.html#organisation",
    "href": "index.html#organisation",
    "title": "TP de Biométrie Semestre 4",
    "section": "Organisation",
    "text": "Organisation\n\nVolume de travail\nLes travaux pratiques et TEA de biométrie auront lieu entre le 19 mars et le 5 avril 2024 :\n\nEntre le mardi 19 et le lundi 25 mars : 1 séance de TP d’1h30 et 1 séance de TEA d’1h30\nEntre le mardi 2 et le vendredi 5 avril : 1 séance de TP d’1h30 et 1 séance de TEA d’1h30\n\n\nTous les TP ont lieu dans les salles du Pôle Communication, Multimédia, Réseaux. Tous les TEA sont à distance.\nAu total, chaque groupe aura donc 2 séances de TP et 2 séances de TEA, soit un total de 6 heures prévues dans vos emplois du temps. C’est peu pour atteindre les objectifs fixés et il y aura donc évidemment du travail personnel à fournir en dehors de ces séances. J’estime que vous devrez fournir 3 à 6 heures de travail personnel en plus des séances prévues dans votre emploi du temps. Attention donc : pensez bien à prévoir du temps dans vos plannings car le travail personnel est essentiel pour progresser dans cette matière. J’insiste sur l’importance de faire l’effort dès maintenant : vous allez en effet avoir des enseignements qui reposent sur l’utilisation de ces logiciels jusqu’à la fin du S6 (y compris pendant vos stages et, très vraisemblablement, dans vos futurs masters également). C’est donc maintenant qu’il faut acquérir des automatismes, cela vous fera gagner énormément de temps ensuite.\n\n\nModalités d’enseignement\nPour suivre cet enseignement vous pourrez utiliser les ordinateurs de l’université, mais je ne peux que vous encourager à utiliser vos propres ordinateurs, sous Windows, Linux ou MacOS. Lors de vos futurs stages et pour rédiger vos comptes-rendus de TP, vous utiliserez le plus souvent vos propres ordinateurs, autant prendre dès maintenant de bonnes habitudes en installant les logiciels dont vous aurez besoin tout au long de votre licence. Si vous n’avez pas suivi la biométrie du semestre 3 et que les logiciels R et RStudio ne sont pas encore installés sur vos ordinateurs, suivez la procédure décrite ici. Si vous ne possédez pas d’ordinateur, manifestez vous rapidement auprès de moi car des solutions existent (prêt par l’université, travail sur tablette via RStudio cloud…).\n\n\n\n\n\n\nImportant\n\n\n\nL’essentiel du contenu de cet enseignement peut être abordé en autonomie, à distance, grâce à ce livre en ligne, aux ressources mises à disposition sur Moodle et à votre ordinateur personnel. Cela signifie que la présence physique lors des séances de TP n’est pas obligatoire.\n\n\nPlus que des séances de TP classiques, considérez plutôt qu’il s’agit de permanences non-obligatoires : si vous pensez avoir besoin d’aide, si vous avez des points de blocage ou des questions sur le contenu de ce document ou sur les exercices demandés, alors venez poser vos questions lors des séances de TP. Vous ne serez d’ailleurs pas tenus de rester pendant 1h30 : si vous obtenez une réponse en 10 minutes et que vous préférez travailler ailleurs, vous serez libres de repartir !\nDe même, si vous n’avez pas de difficulté de compréhension, que vous n’avez pas de problème avec les exercices de ce livre en ligne, votre présence n’est pas requise : tant que le travail demandé est fait, libre à vous de choisir votre façon de travailler. Bien entendu, si vous souhaitez venir en salle de TP pour travailler au calme et dans un cadre plus formel, même si vous n’avez pas de questions à poser : aucun problème, vous y serez toujours les bienvenus et je serai présent systématiquement, pour toutes les séances et tous les groupes.\nCe fonctionnement très souple a de nombreux avantages :\n\nvous vous organisez comme vous le souhaitez\nvous ne venez que lorsque vous en avez vraiment besoin\ncelles et ceux qui se déplacent reçoivent une aide personnalisée\nvous travaillez sur vos ordinateurs\nles effectifs étant réduits, c’est aussi plus confortable pour moi !\n\nToutefois, pour que cette organisation fonctionne, cela demande de la rigueur de votre part, en particulier sur la régularité du travail que vous devez fournir. Si la présence en salle de TP n’est pas requise, le travail demandé est bel et bien obligatoire ! Si vous venez en salle de TP sans avoir travaillé en amont, vous risquez de perdre votre temps car vous passerez votre séance à lire et suivre ce livre en ligne, choses que vous pouvez très bien faire chez vous. De même, si vous attendez le 13 avril pour vous y mettre, je ne pourrais pas grand chose pour vous. Je le répète, outre les heures de TP/TEA prévus dans vos emplois du temps, vous devez prévoir au moins 3 à 6 heures de travail personnel supplémentaire.\nJe vous laisse donc une grande liberté d’organisation. À vous d’en tirer le maximum et de faire preuve du sérieux nécessaire.\n\n\nUtilisation de Slack\nComme au semestre précédent, nous pourrons échanger sur l’application Slack. Si vous ne l’avez pas encore fait (vous êtes une vingtaine dans ce cas !), créez-vous un compte en ligne et installez le logiciel sur votre ordinateur (il existe aussi des versions pour tablettes et smartphones). Lorsque vous aurez installé le logiciel, cliquez sur ce lien pour vous connecter à notre espace de travail commun intitulé L2 SV 23-24 / EC outils (ce lien expire régulièrement : faites moi signe s’il n’est plus valide). C’est le même espace de travail qu’au semestre précédent et si vous vous y êtes déjà connecté cet automne, vous n’avez plus qu’à relancer le logiciel.\nVous verrez que 3 “chaînes” sont disponibles :\n\n#général : c’est là que les questions liées à l’organisation générale du cours, des TP et TEA, des évaluations, etc. doivent être posées. Si vous ne savez pas si une séance de permanence a lieu, posez la question ici.\n#questions-rstudio : c’est ici que toutes les questions pratiques liées à l’utilisation de R et RStudio devront êtres posées. Problèmes de syntaxe, problèmes liés à l’interface, à l’installation des packages ou à l’utilisation des fonctions, à la création des graphiques, à la manipulation des tableaux… Tout ce qui concerne directement les logiciels sera traité ici. Vous êtes libres de poser des questions, de poster des captures d’écran, des morceaux de code, des messages d’erreur. Et vous êtes bien entendus vivement encouragés à vous entraider et à répondre aux questions de vos collègues. Je n’interviendrai ici que pour répondre aux questions laissées sans réponse ou si les réponses apportées sont inexactes. Le fonctionnement est celui d’un forum de discussion instantané. Vous en tirerez le plus grand bénéfice en participant et en n’ayant pas peur de poser des questions, même si elles vous paraissent idiotes. Rappelez-vous toujours que si vous vous posez une question, d’autres se la posent aussi probablement.\n#questions-stats : C’est ici que vous pourrez poser vos questions liées aux méthodes statistiques ou aux choix des modèles de dynamique des populations. Tout ce qui ne concerne pas directement l’utilisation du logiciel (comme par exemple le choix d’un test ou des hypothèses nulles et alternatives, la démarche d’analyse, la signification de tel paramètre ou estimateur, le principe de telle ou telle méthode…) peut être discuté ici. Comme pour le canal #questions-rstudio, vous êtes encouragés à vous entraider et à répondre aux questions de vos collègues.\n\nAinsi, quand vous travaillerez à vos TP ou TEA, que vous soyez installés chez vous ou en salle de TP, prenez l’habitude de garder Slack ouvert sur votre ordinateur. Même si vous n’avez pas de question à poser, votre participation active pour répondre à vos collègues est souhaitable et souhaitée. Je vous incite donc fortement à vous entraider : c’est très formateur pour celui qui explique, et celui qui rencontre une difficulté a plus de chances de comprendre si c’est quelqu’un d’autre qui lui explique plutôt que la personne qui a rédigé les instructions mal comprises.\nCe document est fait pour vous permettre d’avancer en autonomie et vous ne devriez normalement pas avoir beaucoup besoin de moi si votre lecture est attentive. L’expérience montre en effet que la plupart du temps, il suffit de lire correctement les paragraphes précédents et/ou suivants pour obtenir la réponse à ses questions. J’essaie néanmoins de rester disponible sur Slack pendant les séances de TP et de TEA de tous les groupes. Cela veut donc dire que même si votre groupe n’est pas en TP, vos questions ont des chances d’être lues et de recevoir des réponses dès que d’autres groupes sont en TP ou TEA. Vous êtes d’ailleurs encouragés à échanger sur Slack aussi pendant vos phases de travail personnel."
  },
  {
    "objectID": "index.html#progression-conseillée",
    "href": "index.html#progression-conseillée",
    "title": "TP de Biométrie Semestre 4",
    "section": "Progression conseillée",
    "text": "Progression conseillée\nSi vous avez suivi le document de prise en main de R et RStudio du semestre 3, vous savez que pour apprendre à utiliser ces logiciels, il faut faire les choses soi-même, ne pas avoir peur des messages d’erreurs (il faut d’ailleurs apprendre à les déchiffrer pour comprendre d’où viennent les problèmes), essayer maintes fois, se tromper beaucoup, recommencer, et surtout, ne pas se décourager. J’utilise ce logiciel presque quotidiennement depuis plus de 15 ans et à chaque session de travail, je rencontre des messages d’erreur. Avec suffisamment d’habitude, on apprend à les déchiffrer, et on corrige les problèmes en quelques secondes. Ce livre est conçu pour vous faciliter la tâche, mais ne vous y trompez pas, vous rencontrerez des difficultés, et c’est normal. C’est le prix à payer pour profiter de la puissance du meilleur logiciel permettant d’analyser des données, de produire des graphiques de qualité et de réaliser toutes les statistiques dont vous aurez besoin d’ici la fin de vos études et au-delà.\nPour que cet apprentissage soit le moins problématique possible, il convient de prendre les choses dans l’ordre. C’est la raison pour laquelle les 3 chapitres de ce livre doivent être lus dans l’ordre, et les exercices d’application faits au fur et à mesure de la lecture.\nIdéalement, voilà les étapes que vous devriez avoir franchi chaque semaine :\n\nÀ l’issue de la première séance de TP et de la première séance de TEA, vous devriez avoir compris comment calculer et interpréter des résumés statistiques de vos jeux de données (c’est le premier chapitre de ce livre en ligne). Vous devriez en particulier être capable de calculer des estimateurs de position (moyennes, médianes, quartiles…) et de dispersion (variances, écart-types, intervalles inter-quartiles…) sur des variables numériques, et ce, pour plusieurs modalités d’une variable catégorielle ou pour chaque combinaison de modalités de plusieurs variables catégorielles (par exemple, quelles sont les moyennes et variances des longueurs de becs pour chaque espèce de manchots et chaque sexe). Vous devrez donc être capables d’utiliser les fonctions group_by() et summarise() du package dplyr. Cela suppose bien sûr que vous soyez au clair sur les pré-requis évoqués plus haut (Section 1) avant d’aborder le premier chapitre de ce livre en ligne.\nÀ l’issue de la seconde séance de TP, Vous devrez être capables de distinguer la notion de dispersion de celle de précision. Vous devrez être capable d’expliquer clairement la différence entre ces 2 notions, et vous devrez savoir à quoi servent les indices de dispersion et d’incertitude. Vous devrez être capables de calculer des indices d’incertitude, en particulier l’erreur standard de la moyenne (ou erreur type) et l’intervalle de confiance de la moyenne (chapitre 2). Vous devrez en outre être capables de produire des graphiques sur lesquels apparaissent des barres d’incertitude (erreurs standards ou intervalles de confiance, chapitre 3). Là encore, cela suppose que vous soyez au clair avec les représentations graphiques abordées au semestre 3 (comment produire un graphique avec ggplot2, quel graphique choisir pour quelles données et quel objectif ?…)"
  },
  {
    "objectID": "index.html#évaluations",
    "href": "index.html#évaluations",
    "title": "TP de Biométrie Semestre 4",
    "section": "Évaluation(s)",
    "text": "Évaluation(s)\nL’évaluation de la partie “Biométrie” de l’EC “Outils pour l’étude et la compréhension du vivant 3” sera conduite par mes collègues en charge des cours magistraux, travaux dirigés, et travaux pratiques “classiques” (Fanny Cusset et Gérard Blanchard). Il est bien évident toutefois que mes collègues attendent une bonne maîtrise des notions développées ici, et qu’au-delà de la biométrie, les autres collègues intervenant dans l’EC “outils pour l’étude et la compréhension du vivant 3” attendent eux aussi que vous mettiez en pratique ce que vous apprenez ici dans vos futurs compte-rendus de TP."
  },
  {
    "objectID": "index.html#licence",
    "href": "index.html#licence",
    "title": "TP de Biométrie Semestre 4",
    "section": "Licence",
    "text": "Licence\nCe livre est ligne est sous licence Creative Commons (CC BY-NC-ND 4.0)\n\n\n\n\n\nVous êtes autorisé à partager, copier, distribuer et communiquer ce matériel par tous moyens et sous tous formats, tant que les conditions suivantes sont respectées :\n\n\n Attribution : vous devez créditer ce travail (donc citer son auteur), fournir un lien vers ce livre en ligne, intégrer un lien vers la licence Creative Commons et indiquer si des modifications du contenu original ont été effectuées. Vous devez indiquer ces informations par tous les moyens raisonnables, sans toutefois suggérer que l’auteur vous soutient ou soutient la façon dont vous avez utilisé son travail.\n\n\n Pas d’Utilisation Commerciale : vous n’êtes pas autorisé à faire un usage commercial de cet ouvrage, ni de tout ou partie du matériel le composant. Cela comprend évidemment la diffusion sur des plateformes de partage telles que studocu.com qui tirent profit d’œuvres dont elles ne sont pas propriétaires, souvent à l’insu des auteurs.\n\n\n Pas de modifications : dans le cas où vous effectuez un remix, que vous transformez, ou créez à partir du matériel composant l’ouvrage original, vous n’êtes pas autorisé à distribuer ou mettre à disposition l’ouvrage modifié.\n\n\n Pas de restrictions complémentaires : vous n’êtes pas autorisé à appliquer des conditions légales ou des mesures techniques qui restreindraient légalement autrui à utiliser cet ouvrage dans les conditions décrites par la licence."
  },
  {
    "objectID": "03-graphiques.html#pré-requis",
    "href": "03-graphiques.html#pré-requis",
    "title": "3  Visualiser l’incertitude et la dispersion",
    "section": "3.1 Pré-requis",
    "text": "3.1 Pré-requis\nNous avons ici besoin des packages suivants :\n\nlibrary(tidyverse)\nlibrary(palmerpenguins)\nlibrary(nycflights13)\n\nPensez à les charger en mémoire si ce n’est pas déjà fait ou si vous venez de démarrer une nouvelle session de travail.\nIl existe plusieurs façons de représenter visuellement les positions, les dispersions et les incertitudes. Concernant les positions et les dispersions tout d’abord, nous avons déjà vu plusieurs façons de faire au semestre 3, en particulier dans les parties consacrées aux histogrammes, aux stripcharts et aux boxplots. Nous reprenons ici brièvement chacun de ces 3 types de graphique afin de les remettre en contexte avec ce que nous avons appris ici.\nDans un dernier temps, nous verrons comment visualiser l’incertitude associée à des calculs de moyennes ou de variances grâce aux barres d’erreurs ou aux encoches des boîtes à moustaches."
  },
  {
    "objectID": "03-graphiques.html#position-et-dispersion-les-histogrammes",
    "href": "03-graphiques.html#position-et-dispersion-les-histogrammes",
    "title": "3  Visualiser l’incertitude et la dispersion",
    "section": "3.2 Position et dispersion : les histogrammes",
    "text": "3.2 Position et dispersion : les histogrammes\nJe vous renvoie à la partie sur les histogrammes du livre en ligne de biométrie du semestre 3 si vous avez besoin de vous rafraîchir la mémoire. Jetez aussi un œil la partie sur les histogrammes facettés.\nLes histogrammes permettent de déterminer à la fois où se trouvent les valeurs les plus fréquemment observées (la position du pic principal correspond à la tendance centrale), et la dispersion (ou variabilité) des valeurs autour de la tendance centrale. Par exemple, la fonction facet_grid() permet de faire des histogrammes des températures pour chaque aéroport de New York et chaque mois de l’année 2013 :\n\nweather |&gt; \n  mutate(temp_celsius = (temp - 32) / 1.8) |&gt; \n  ggplot(aes(x = temp_celsius, fill = factor(month))) +\n  geom_histogram(bins = 20, color = \"grey20\", show.legend = FALSE) +\n  facet_grid(factor(month) ~ origin, scales = \"free_y\") +\n  labs(x = \"Températures (ºC)\", y = \"Fréquence\") +\n  theme_bw()\n\nWarning: Removed 1 rows containing non-finite values (`stat_bin()`).\n\n\n\n\n\nIci, 36 histogrammes sont produits. Ils permettent de constater que :\n\nles températures évoluent à peu près de la même façon dans les 3 aéroports (les 3 colonnes de graphiques se ressemblent beaucoup).\nles températures moyennes sont plus faibles en hiver qu’en été, et qu’elles sont intermédiaires au printemps et à l’automne. C’est bien la position des pics sur l’axe des abscisses qui nous renseigne là-dessus. On sait aussi que les températures moyennes les plus fortes sont autour de 25ºC en juillet, alors que ces mêmes températures moyennes sont proches de 0ºC en janvier, février et décembre.\nla variabilité des températures est comparable pour la plupart des mois de l’année, avec une exception au mois d’août où la dispersion des valeurs semble plus limitée. Cette fois, c’est l’étalement de l’histogramme qui nous renseigne sur la dispersion."
  },
  {
    "objectID": "03-graphiques.html#position-et-dispersion-les-stripcharts",
    "href": "03-graphiques.html#position-et-dispersion-les-stripcharts",
    "title": "3  Visualiser l’incertitude et la dispersion",
    "section": "3.3 Position et dispersion : les stripcharts",
    "text": "3.3 Position et dispersion : les stripcharts\nUne autre façon de visualiser à la fois les tendances centrales et les dispersions consiste à produire un nuage de points “stripchart”. Là encore, je vous renvoie à la partie sur les stripcharts du livre en ligne de biométrie du semestre 3 si vous avez besoin de vous rafraîchir la mémoire.\n\nweather |&gt; \n  mutate(temp_celsius = (temp - 32) / 1.8) |&gt; \n  ggplot(aes(x = factor(month), y = temp_celsius, fill = factor(month))) +\n  geom_jitter(shape = 21, color = \"grey20\", show.legend = FALSE,\n              width = 0.15, height = 0,\n              alpha = 0.5) +\n  facet_wrap(~ origin, ncol = 1) +\n  labs(x = \"Mois\", y = \"Températures (ºC)\") +\n  theme_bw()\n\nWarning: Removed 1 rows containing missing values (`geom_point()`).\n\n\n\n\n\nCette fois, nous visualisons la totalité des données disponibles, et non les données regroupées dans des classes plus ou moins arbitraires. Mais là encore, on peut facilement comparer la position de chaque série de données : pour les mois d’été, les températures sont plus élevées que pour les mois d’hiver. Et la dispersion des données est aussi facile à comparer entre les mois. Par exemple, la variabilité des températures en janvier est nettement supérieure à celle du mois de février. C’est ici l’étendue du nuage de points sur l’axe des ordonnées qui nous permet de le dire."
  },
  {
    "objectID": "03-graphiques.html#position-et-dispersion-les-boxplots",
    "href": "03-graphiques.html#position-et-dispersion-les-boxplots",
    "title": "3  Visualiser l’incertitude et la dispersion",
    "section": "3.4 Position et dispersion : les boxplots",
    "text": "3.4 Position et dispersion : les boxplots\nLa dernière façon classique de visualiser à la fois les tendances centrales et les dispersions consiste à produire un graphique boîtes à moustaches, ou “boxplot”. Là encore, je vous renvoie à la partie sur les boxplots du livre en ligne de biométrie du semestre 3 si vous avez besoin de vous rafraîchir la mémoire.\n\nweather |&gt; \n  mutate(temp_celsius = (temp - 32) / 1.8) |&gt; \n  ggplot(aes(x = factor(month), y = temp_celsius, fill = factor(month))) +\n  geom_boxplot(show.legend = FALSE, alpha = 0.5) +\n  facet_wrap(~ origin, ncol = 1) +\n  labs(x = \"Mois\", y = \"Températures (ºC)\") +\n  theme_bw()\n\nWarning: Removed 1 rows containing non-finite values (`stat_boxplot()`).\n\n\n\n\n\nVous voyez que le code est très proche pour produire un stripchart ou un boxplot. Comme indiqué au semestre 3, les différents éléments de chaque boîte nous renseignent sur la position et sur la dispersion des données pour chaque mois et chaque aéroport :\n\nLa limite inférieure de la boîte correspond au premier quartile : 25% des données de l’échantillon sont situées au-dessous de cette valeur.\nLa limite supérieure de la boîte correspond au troisième quartile : 75% des données de l’échantillon sont situées au-dessous de cette valeur.\nLe segment épais à l’intérieur de la boîte correspond au second quartile : c’est la médiane de l’échantillon, qui nous renseigne sur la position de la distribution. 50% des données de l’échantillon sont situées au-dessus de cette valeur, et 50% au-dessous.\nLa hauteur de la boîte correspond à l’étendue (ou intervalle) interquartile ou Inter Quartile Range (IQR) en anglais. On trouve dans cette boîte 50% des observations de l’échantillon. C’est une mesure de la dispersion des 50% des données les plus centrales. Une boîte plus allongée indique donc une plus grande dispersion.\nLes moustaches correspondent à des valeurs qui sont en dessous du premier quartile (pour la moustache du bas) et au-dessus du troisième quartile (pour la moustache du haut). La règle utilisée dans R est que ces moustaches s’étendent jusqu’aux valeurs minimales et maximales de l’échantillon, mais elles ne peuvent en aucun cas s’étendre au-delà de 1,5 fois la hauteur de la boîte (1,5 fois l’IQR) vers le haut et le bas. Si des points apparaissent au-delà des moustaches (vers le haut ou le bas), ces points sont appelés “outliers”. On peut en observer ici pour plusieurs mois et pour les 3 aéroports (par exemple, en avril dans les 3 aéroports). Ce sont des points qui s’éloignent du centre de la distribution de façon importante puisqu’ils sont au-delà de 1,5 fois l’IQR de part et d’autre du premier ou du troisième quartile. Il peut s’agir d’anomalies de mesures, d’anomalies de saisie des données, ou tout simplement, d’enregistrements tout à fait valides mais atypiques ou extrêmes ; ll ne s’agit donc pas toujours de point aberrants. J’attire votre attention sur le fait que la définition de ces outliers est relativement arbitraire. Nous pourrions faire le choix d’étendre les moustaches jusqu’à 1,8 fois l’IQR (ou 2, ou 2,5). Nous observerions alors beaucoup moins d’outliers. D’une façons générale, la longueur des moustaches renseigne sur la variabilité des données en dehors de la zone centrale. Plus elles sont longues, plus la variabilité est importante. Très souvent, l’examen attentif des outliers est utile car il nous permet d’en apprendre plus sur le comportement extrême de certaines observations.\n\nLorsque les boîtes ont une forme à peu près symétrique de part et d’autre de la médiane (c’est le cas pour cet exemple dans la plupart des catégories), cela signifie qu’un histogramme des mêmes données serait symétrique également.\nLes stripcharts et les boxplots sont donc un bon moyen de comparer rapidement la position et la dispersion d’un grand nombre de séries de données : ici, en quelques lignes de code, nous en comparons 12 pour chacun des 3 aéroports de New York.\nLes histogrammes sont plus utiles lorsqu’il y a moins de catégories à comparer. Ils permettent en outre de mieux visualiser les distributions non symétriques, ou qui présentent plusieurs pics (distribution bi- ou poly-modales)."
  },
  {
    "objectID": "03-graphiques.html#visualiser-lincertitude-les-barres-derreur",
    "href": "03-graphiques.html#visualiser-lincertitude-les-barres-derreur",
    "title": "3  Visualiser l’incertitude et la dispersion",
    "section": "3.5 Visualiser l’incertitude : les barres d’erreur",
    "text": "3.5 Visualiser l’incertitude : les barres d’erreur\nComme évoqué plus haut, il est important de ne pas confondre dispersion et incertitude. Lorsque l’on visualise des moyennes calculées à partir des données d’un échantillon, il est important de faire apparaître des barres d’erreurs, qui correspondent en général :\n\nsoit à l’erreur standard de la moyenne\nsoit à l’intervalle de confiance à 95% de la moyenne\n\nPuisque deux choix sont possibles, il sera important de préciser systématiquement dans la légende du graphique, la nature des barres représentées. Commençons par visualiser les températures mensuelles avec les erreurs standards. Pour cela, je reprends le tableau temperatures_se créé précédemment :\n\ntemperatures_se |&gt; \n  ggplot(aes(x = factor(month), y = moyenne)) +\n  geom_line(aes(group = 1)) +\n  geom_point() +\n  geom_errorbar(aes(ymin = moyenne - erreur_standard,\n                    ymax = moyenne + erreur_standard),\n                width = 0.1) +\n  facet_wrap(~origin, ncol = 1) +\n  labs(x = \"Mois\", \n       y = \"Moyenne des températures quotidiennes maximales (ºC)\") +\n  theme_bw()\n\n\n\n\nFigure 3.1: Températures moyennes mensuelles observées en 2013 dans les 3 aéroports de New York. Les barres d’erreur sont les erreurs standard\n\n\n\n\nVous remarquerez que :\n\nj’associe factor(month), et non simplement month, à l’axe des x afin d’avoir, sur l’axe des abscisses, des chiffres cohérents allant de 1 à 12, et non des chiffres à virgule.\nl’argument group = 1 doit être ajouté pour que la ligne reliant les points apparaisse. En effet, les lignes sont censées relier des points qui appartiennent à une même série temporelle. Or ici, nous avons transformé month en facteur. Préciser group = 1 permet d’indiquer à geom_line() que toutes les catégories du facteur month appartiennent au même groupe, que ce facteur peut être considéré comme une variable continue, et qu’il est donc correct de relier les points.\nla fonction geom_errorbar() contient de nouvelles caractéristiques esthétiques qu’il nous faut obligatoirement renseigner : les extrémités inférieures et supérieures des barres d’erreur. Il nous faut donc associer 2 variables à ces caractéristiques esthétiques. Ici, nous utilisons moyenne - erreur_std pour la borne inférieure des barres d’erreur, et moyenne + erreur_std pour la borne supérieure. Les variables moyenne et erreur_standard faisant partie du tableau temperatures_se, geom_errorbar() les trouve sans difficulté.\nl’argument width de la fonction geom_errorbar() permet d’indiquer la longueur des segments horizontaux qui apparaissent à chaque extrémité des barres d’erreur.\n\nIci, bien que moins lisible, on peut aussi faire apparaître les trois courbes sur le même graphique, afin de mieux visualiser les similarités des fluctuations de températures entre les 3 aéroports :\n\ntemperatures_se |&gt; \n  ggplot(aes(x = factor(month), y = moyenne, color = origin, group = origin)) +\n  geom_line() +\n  geom_point() +\n  geom_errorbar(aes(ymin = moyenne - erreur_standard,\n                    ymax = moyenne + erreur_standard),\n                width = 0.1) +\n  labs(x = \"Mois\", \n       y = \"Moyenne des températures quotidiennes maximales (ºC)\",\n       color = \"Aéroport\") +\n  theme_bw()\n\n\n\n\nFigure 3.2: Températures moyennes mensuelles observées en 2013 dans les 3 aéroports de New York. Les barres d’erreur sont les erreurs standard.\n\n\n\n\nNous pouvons arriver au même résultats en utilisant le tableau temperature_se_bornes, qui contient des variables différentes :\n\ntemperature_se_bornes |&gt; \n  ggplot(aes(x = factor(month), y = moyenne, color = origin, group = origin)) +\n  geom_line() +\n  geom_point() +\n  geom_errorbar(aes(ymin = moyenne_moins_se,\n                    ymax = moyenne_plus_se),\n                width = 0.1) +\n  labs(x = \"Mois\", \n       y = \"Moyenne des températures quotidiennes maximales (ºC)\",\n       color = \"Aéroport\") +\n  theme_bw()\n\n\n\n\nFigure 3.3: Températures moyennes mensuelles observées en 2013 dans les 3 aéroports de New York. Les barres d’erreur sont les erreurs standard.\n\n\n\n\nDe la même façon, nous pouvons parfaitement faire apparaître, au lieu des erreurs standards, les intervalles de confiance à 95% de chaque valeur de température moyenne. Il nous suffit pour cela d’utiliser le tableau temperatures_ci qui contient les valeurs de moyennes et des bornes supérieures et inférieures de ces intervalles :\n\ntemperature_ci |&gt; \n  ggplot(aes(x = factor(month), y = moyenne, group = 1)) +\n  geom_line() +\n  geom_point() +\n  geom_errorbar(aes(ymin = ci_borne_inf, ymax = ci_borne_sup), width = 0.1) +\n  facet_wrap(~origin, ncol = 1) +\n  labs(x = \"Mois\", \n       y = \"Moyenne des températures quotidiennes maximales (ºC)\",\n       color = \"Aéroport\") +\n  theme_bw()\n\n\n\n\nFigure 3.4: Températures moyennes mensuelles observées en 2013 dans les 3 aéroports de New York. Les barres d’erreur sont les intervalels de confiance à 95% des moyenes mensuelles.\n\n\n\n\nComme vous voyez, les barres d’erreurs sont maintenant plus longues que sur la Figure 3.1. C’est normal car rappelez-vous que les intervalles de confiance sont à peu près équivalents à 2 fois les erreurs standards. L’intérêt de représenter les intervalles de confiance est qu’ils sont directement liés aux tests statistiques que nous aborderons en L3. Globalement, quand 2 séries de données ont des intervalles de confiance qui se chevauchent largement (comme les mois de janvier et février par exemple), alors, un test d’hypothèses conclurait presque toujours à l’absence de différence significative entre les 2 groupes. À l’inverse, quand 2 séries de données ont des intervalles de confiance qui ne se chevauchent pas du tout (comme les mois de mars et d’avril par exemple), alors, un test d’hypothèses conclurait presque toujours à l’existence d’une différence significative entre les 2 groupes. Lorsque les intervalles de confiance entre 2 catégories se chevauchent faiblement ou partiellement (comme entre les mois de juin et juillet pour l’aéroport LGA), la situation est moins tranchée, et nous devrons nous en remettre aux résultats du test pour savoir si la différence observée devrait être considérée comme significative ou non."
  },
  {
    "objectID": "03-graphiques.html#visualiser-lincertitude-les-boîtes-à-moustaches",
    "href": "03-graphiques.html#visualiser-lincertitude-les-boîtes-à-moustaches",
    "title": "3  Visualiser l’incertitude et la dispersion",
    "section": "3.6 Visualiser l’incertitude : les boîtes à moustaches",
    "text": "3.6 Visualiser l’incertitude : les boîtes à moustaches\nOutre les informations de position et de dispersion, les boîtes à moustaches permettent également de visualiser l’incertitude associée aux médianes. Il suffit pour cela d’ajouter l’argument notch = TRUE dans la fonction geom_boxplot() :\n\nweather |&gt; \n  mutate(temp_celsius = (temp - 32) / 1.8) |&gt; \n  ggplot(aes(x = factor(month), y = temp_celsius, fill = factor(month))) +\n  geom_boxplot(show.legend = FALSE, alpha = 0.5, notch = TRUE) +\n  facet_wrap(~ origin, ncol = 1) +\n  labs(x = \"Mois\", y = \"Températures (ºC)\") +\n  theme_bw()\n\nWarning: Removed 1 rows containing non-finite values (`stat_boxplot()`).\n\n\n\n\n\nDes encoches ont été ajoutées autour de la médiane de chaque boîte à moustache. Ces encoches sont des encoches d’incertitudes. Les limites inférieures et supérieures de ces encoches correspondent aux bornes inférieures et supérieures de l’intervalle de confiance à 95% des médianes. Comme pour les moyennes, le chevauchement ou l’absence de chevauchement entre les encoches de 2 séries de données nous renseigne sur l’issue probable des futurs tests statistiques que nous serions amenés à réaliser. Il sera donc important de bien examiner ces encoches en amont des tests statistiques pour éviter de faire/dire des bêtises…"
  },
  {
    "objectID": "03-graphiques.html#sec-ploterrbar",
    "href": "03-graphiques.html#sec-ploterrbar",
    "title": "3  Visualiser l’incertitude et la dispersion",
    "section": "3.7 Exercice",
    "text": "3.7 Exercice\n\nAvec le tableau penguins, calculez les grandeurs suivantes pour chaque espèce de manchot et chaque sexe :\n\n\nla moyenne de la longueur des nageoires\nla variance de la longueur des nageoires\nl’écart-type de la longueur des nageoires\nl’erreur standard de la longueur moyenne des nageoires\nla moyenne de la masse corporelle\nla variance de la masse corporelle\nl’écart-type de la masse corporelle\nl’erreur standard de la masse corporelle moyenne\n\nAttention : pensez à retirer les individus dont le sexe est inconnu.\n\nVérifiez avec la fonction skim() que les moyennes et écart-types calculés ci-dessus sont corrects.\nAvec ces données synthétiques faites le graphique suivant :"
  },
  {
    "objectID": "04-corrections.html#correction-de-lexercice-de-la-sec-exo10",
    "href": "04-corrections.html#correction-de-lexercice-de-la-sec-exo10",
    "title": "4  Correction des exercices",
    "section": "4.1 Correction de l’exercice de la Section 1.2.5",
    "text": "4.1 Correction de l’exercice de la Section 1.2.5\n\nAvec le tableau diamonds du package ggplot2, faites un tableau indiquant combien de diamants de chaque couleur on dispose.\n\n\ndiamonds |&gt; \n  count(color)\n\n# A tibble: 7 × 2\n  color     n\n  &lt;ord&gt; &lt;int&gt;\n1 D      6775\n2 E      9797\n3 F      9542\n4 G     11292\n5 H      8304\n6 I      5422\n7 J      2808\n\n\n\nExaminez le tableau weather du package nycflights13 et lisez son fichier d’aide pour comprendre à quoi correspondent les données et comment elles ont été acquises.\n\n\nweather\n?weahter\n\n\nÀ partir du tableau weather faites un tableau indiquant les vitesses de vents minimales, maximales et moyennes, enregistrées chaque mois dans chaque aéroport de New York. Indice : les 3 aéroports de New York sont Newark, LaGuardia Airport et John F. Kennedy, notés respectivement EWR, LGA et JFK dans la variable origin.\n\n\nwindy &lt;- weather |&gt;\n  summarise(max_wind = max(wind_speed, na.rm = TRUE),\n            min_wind = min(wind_speed, na.rm = TRUE),\n            moy_wind = mean(wind_speed, na.rm = TRUE),\n            .by = c(origin, month))\nwindy\n\n# A tibble: 36 × 5\n   origin month max_wind min_wind moy_wind\n   &lt;chr&gt;  &lt;int&gt;    &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n 1 EWR        1     42.6        0     9.87\n 2 EWR        2   1048.         0    12.2 \n 3 EWR        3     29.9        0    11.6 \n 4 EWR        4     25.3        0     9.63\n 5 EWR        5     33.4        0     8.49\n 6 EWR        6     34.5        0     9.55\n 7 EWR        7     20.7        0     9.15\n 8 EWR        8     21.9        0     7.62\n 9 EWR        9     23.0        0     8.03\n10 EWR       10     26.5        0     8.32\n# ℹ 26 more rows\n\n\n\nSachant que les vitesses du vent sont exprimées en miles par heure, certaines valeurs sont-elles surprenantes ? À l’aide de la fonction filter(), éliminez la ou les valeurs aberrantes.\n\nOui, les vitesses de vent supérieures à 100 mph devraient être rares :\n\nwindy |&gt; \n  filter(max_wind &gt; 100)\n\n# A tibble: 1 × 5\n  origin month max_wind min_wind moy_wind\n  &lt;chr&gt;  &lt;int&gt;    &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n1 EWR        2    1048.        0     12.2\n\n\nIci, 1048 mph est impossible. Il s’agit soit d’un dysfonctionnement de l’appareil de mesure, soit d’une erreur de saisie. Pour éliminer cette valeur aberrante, on utilise filter() :\n\nwindy2 &lt;- weather |&gt;\n  filter(wind_speed &lt;= 500) |&gt;\n  summarise(max_wind = max(wind_speed, na.rm = TRUE),\n            min_wind = min(wind_speed, na.rm = TRUE),\n            moy_wind = mean(wind_speed, na.rm = TRUE),\n            .by = c(origin, month))\nwindy2\n\n# A tibble: 36 × 5\n   origin month max_wind min_wind moy_wind\n   &lt;chr&gt;  &lt;int&gt;    &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n 1 EWR        1     42.6        0     9.87\n 2 EWR        2     31.1        0    10.7 \n 3 EWR        3     29.9        0    11.6 \n 4 EWR        4     25.3        0     9.63\n 5 EWR        5     33.4        0     8.49\n 6 EWR        6     34.5        0     9.55\n 7 EWR        7     20.7        0     9.15\n 8 EWR        8     21.9        0     7.62\n 9 EWR        9     23.0        0     8.03\n10 EWR       10     26.5        0     8.32\n# ℹ 26 more rows\n\n\n\nEn utilisant les données de vitesse de vent du tableau weather, produisez le graphique suivant :\n\n\nweather |&gt;\n  filter(wind_speed &lt; 500) |&gt;\n  ggplot(aes(x = factor(month), y = wind_speed)) +\n  geom_jitter(width = 0.2, height = 0, alpha = 0.2) +\n  labs(x = \"Mois\",\n       y = \"Vitesse du vent (mph)\")\n\n\n\n\n\nÀ votre avis :\n\n\npourquoi les points sont-ils organisés en bandes horizontales ?\n\nParce que l’appareil de mesure enregistre probablement des vitesses de vent arrondies au mile par heure le plus proche (pas de valeurs enregsitrées), ou parce que les valeurs ont été arrondies à l’entier le plus proche avant enregistrement dans la base de données.\n\npourquoi n’y a-t-il jamais de vent entre 0 et environ 3 miles à l’heure (mph) ?\n\nCela est probablement dû au seuil de détection de l’appareil d’enregistrement qui est incapable de détecter des des vitesses inferieures à ce seuil. Cela ne veut pas dire qu’il n’y a jamais eu de vent inférieur à 3 mph.\n\nSachant qu’en divisant des mph par 1.151 on obtient des vitesses en nœuds, que nous apprend cette commande :\n\n\nsort(unique(weather$wind_speed)) / 1.151\n\n [1]   0.000000   2.999427   3.999235   4.999044   5.998853   6.998662\n [7]   7.998471   8.998280   9.998089  10.997897  11.997706  12.997515\n[13]  13.997324  14.997133  15.996942  16.996751  17.996560  18.996368\n[19]  19.996177  20.995986  21.995795  22.995604  23.995413  24.995222\n[25]  25.995030  26.994839  27.994648  28.994457  29.994266  30.994075\n[31]  31.993884  32.993692  33.993501  34.993310  36.992928 910.825873\n\n\nQue l’appareil n’enregistre que des vitesses de vent entières, en nœuds, à partir de 3 nœuds (3, 4, 5, etc.). La transformation en mph n’est probablement effectuées qu’ensuite et explique les erreurs d’arrondis."
  },
  {
    "objectID": "04-corrections.html#correction-de-lexercice-de-la-sec-exo20",
    "href": "04-corrections.html#correction-de-lexercice-de-la-sec-exo20",
    "title": "4  Correction des exercices",
    "section": "4.2 Correction de l’exercice de la Section 1.5.3",
    "text": "4.2 Correction de l’exercice de la Section 1.5.3\nEn utilisant les fonctions de résumé abordées jusqu’ici et le tableau weather, répondez aux questions suivante :\n\nDans quel aéroport de New York les précipitations moyennes ont-elle été les plus fortes en 2013 ?\n\n\nweather |&gt; \n  summarise(precip_moyenne = mean(precip), .by = origin) |&gt; \n  arrange(desc(precip_moyenne))\n\n# A tibble: 3 × 2\n  origin precip_moyenne\n  &lt;chr&gt;           &lt;dbl&gt;\n1 EWR           0.00504\n2 LGA           0.00438\n3 JFK           0.00398\n\n\nLes précipitations horaires moyennes les plus fortes sont enregistrées dans l’aéroport EWR (Newark). Si on s’intéresse plutôt aux précipitations mensuelles :\n\nweather |&gt; \n  group_by(origin, month) |&gt; \n  summarise(precip_tot = sum(precip)) |&gt;       # Cumul de précipitation chaque mois et dans chaqe aéroport\n  summarise(precip_moy = mean(precip_tot)) |&gt;  # Calcul des moyennes mensuelles pour chaque aeroport \n  arrange(desc(precip_moy))                     # Tri par ordre décroissant de précipitations moyennes\n\n`summarise()` has grouped output by 'origin'. You can override using the\n`.groups` argument.\n\n\n# A tibble: 3 × 2\n  origin precip_moy\n  &lt;chr&gt;       &lt;dbl&gt;\n1 EWR          3.66\n2 LGA          3.18\n3 JFK          2.89\n\n\nLogiquement, c’est toujours dans l’aéroport de Newark que les précipitations mensuelles moyennes sont les plus fortes (3,66 pouces par mois en moyenne).\n\nDans quel aéroport de New York la vitesse du vent moyenne était-elle la plus forte en 2013 ? Quelle est cette vitesse ?\n\n\nweather |&gt; \n  summarise(wind_moyenne = mean(wind_speed, na.rm = TRUE),\n            .by = origin) |&gt; \n  arrange(desc(wind_moyenne))\n\n# A tibble: 3 × 2\n  origin wind_moyenne\n  &lt;chr&gt;         &lt;dbl&gt;\n1 JFK           11.5 \n2 LGA           10.6 \n3 EWR            9.46\n\n\nLe vent moyen le plus fort est observé à JFK, et vaut 11.5 miles à l’heure. Attention, ça n’est pas le vent le plus fort observé, mais bien le vent moyen le plus fort.\n\nDans quel aéroport de New York les rafales de vent étaient-elles les plus variables en 2013 ? Quel indice statistique vous donne cette information et quelle est sa valeur ?\n\n\nweather |&gt; \n  summarise(rafales_var = var(wind_gust, na.rm = TRUE),\n            .by = origin) |&gt; \n  arrange(desc(rafales_var))\n\n# A tibble: 3 × 2\n  origin rafales_var\n  &lt;chr&gt;        &lt;dbl&gt;\n1 JFK           37.5\n2 LGA           32.8\n3 EWR           31.2\n\n\nC’est à l’aéroport JFK que les rafales de vent étaient les plus variables en 2013. La variance de 37.5 mph\\(^2\\) nous renseigne sur cette variabilité. Une autre façon d’arriver à cette même conclusion consiste à utiliser la fonction skim() sur la variable wind_gust et les données groupées par aéroport (variable origin) :\n\nweather |&gt; \n  select(origin, wind_gust) |&gt; \n  group_by(origin) |&gt; \n  skim()\n\n\nData summary\n\n\nName\ngroup_by(select(weather, …\n\n\nNumber of rows\n26115\n\n\nNumber of columns\n2\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\nnumeric\n1\n\n\n________________________\n\n\n\nGroup variables\norigin\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\norigin\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nwind_gust\nEWR\n6901\n0.21\n24.14\n5.58\n16.11\n19.56\n23.02\n27.33\n58.69\n▇▅▁▁▁\n\n\nwind_gust\nJFK\n7199\n0.17\n27.56\n6.13\n16.11\n23.02\n26.47\n31.07\n66.75\n▇▇▁▁▁\n\n\nwind_gust\nLGA\n6678\n0.23\n25.14\n5.73\n16.11\n20.71\n24.17\n27.62\n62.14\n▇▅▁▁▁\n\n\n\n\n\nIci, c’est l’indice noté sd qui nous renseigne. Il s’agit de l’écart-type qui est exprimé dans la même unité que les données de départ. La variabilité des rafales de vent est donc bien la plus forte à l’aéroport JFK, avec un écart-type de 6.13 mph.\n\nLes précipitation dans les 3 aéroports de New-York ont-elles une distribution symétrique ?\n\n\nweather |&gt; \n  ggplot(aes(x = precip, fill = origin)) +\n  geom_histogram(alpha = 0.5, show.legend = FALSE) +\n  geom_rug() +\n  facet_wrap(~origin, ncol = 1)\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\nLa distribution des précipitations est très clairement asymétrique, avec un très grand nombre de relevés avec aucune précipitation (ce qui explique la très grande barre à la valeur 0), puis une diminution rapide des fréquences auxquelles les précipitations importantes sont observées. D’ailleurs, même en retirant les enregistrement où aucune précipitation n’est détectée, la distribution n’est pas non plus symétrique :\n\nweather |&gt; \n  filter(precip &gt; 0 ) |&gt; \n  ggplot(aes(x = precip, fill = origin)) +\n  geom_histogram(alpha = 0.5, show.legend = FALSE) +\n  geom_rug() +\n  facet_wrap(~origin, ncol = 1)\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\nQuelle est la température médiane observée en 2013 tous aéroports confondus ?\n\n\nweather |&gt; \n  summarise(temo_med = median(temp, na.rm = TRUE))\n\n# A tibble: 1 × 1\n  temo_med\n     &lt;dbl&gt;\n1     55.4\n\n\nLa température médiane, tous aéroports confondue, observée en 2013, vaut 55.4 degrés Fahrenheit.\n\nTous aéroports confondus, quel est le mois de l’année où la température a été la plus variable en 2013 ? Quelles étaient les températures minimales et maximales observées ce mois-là ?\n\n\nweather |&gt; \n  group_by(month) |&gt; \n  summarise(temp_var = var(temp, na.rm = TRUE),\n            temp_sd  = sd(temp, na.rm = TRUE),\n            temp_min = min(temp, na.rm = TRUE),\n            temp_max = max(temp, na.rm = TRUE)) |&gt; \n  arrange(desc(temp_var))\n\n# A tibble: 12 × 5\n   month temp_var temp_sd temp_min temp_max\n   &lt;int&gt;    &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n 1    11    109.    10.4      21.0     71.1\n 2     1    105.    10.2      10.9     64.4\n 3    12     99.6    9.98     18.0     71.6\n 4     5     93.7    9.68     13.1     93.0\n 5    10     78.3    8.85     33.1     89.1\n 6     4     77.2    8.79     30.9     84.0\n 7     9     71.7    8.47     48.0     95  \n 8     6     56.9    7.55     54.0     93.9\n 9     7     50.7    7.12     64.0    100. \n10     2     48.8    6.98     16.0     55.9\n11     3     39.1    6.25     26.1     60.1\n12     8     27.0    5.19     59       90.0\n\n\nC’est en Novembre que les températures ont été les plus variables avec un écart-type de 10.4 degrés Fahrenheit. Ce même mois, la température minimale observée était de 21ºF et la température maximale de 71.1ºF."
  },
  {
    "objectID": "04-corrections.html#correction-de-lexercice-de-la-sec-ploterrbar",
    "href": "04-corrections.html#correction-de-lexercice-de-la-sec-ploterrbar",
    "title": "4  Correction des exercices",
    "section": "4.3 Correction de l’exercice de la Section 3.7",
    "text": "4.3 Correction de l’exercice de la Section 3.7\n\nAvec le tableau penguins, calculez les grandeurs suivantes pour chaque espèce de manchot et chaque sexe :\n\n\nla moyenne de la longueur des nageoires\nla variance de la longueur des nageoires\nl’écart-type de la longueur des nageoires\nl’erreur standard de la longueur moyenne des nageoires\nla moyenne de la masse corporelle\nla variance de la masse corporelle\nl’écart-type de la masse corporelle\nl’erreur standard de la masse corporelle moyenne\n\nAttention : pensez à retirer les individus dont le sexe est inconnu.\n\nresum &lt;- penguins |&gt; \n  filter(!is.na(sex)) |&gt; \n  summarise(moy_L_nageoire = mean(flipper_length_mm, na.rm = TRUE),\n            var_L_nageoire = var(flipper_length_mm, na.rm = TRUE),\n            sd_L_nageoire = sd(flipper_length_mm, na.rm = TRUE),\n            se_L_nageoire = sd_L_nageoire/sqrt(n()),\n            moy_mass = mean(body_mass_g, na.rm = TRUE),\n            var_mass = var(body_mass_g, na.rm = TRUE),\n            sd_mass = sd(body_mass_g, na.rm = TRUE),\n            se_mass = sd_mass/sqrt(n()),\n            .by = c(species, sex))\n\nresum\n\n\n\n# A tibble: 6 × 10\n  species   sex    moy_L_nageoire var_L_nageoire sd_L_nageoire se_L_nageoire\n  &lt;fct&gt;     &lt;fct&gt;           &lt;dbl&gt;          &lt;dbl&gt;         &lt;dbl&gt;         &lt;dbl&gt;\n1 Adelie    male             192.           43.6          6.60         0.772\n2 Adelie    female           188.           31.3          5.60         0.655\n3 Gentoo    female           213.           15.2          3.90         0.512\n4 Gentoo    male             222.           32.2          5.67         0.726\n5 Chinstrap female           192.           33.1          5.75         0.987\n6 Chinstrap male             200.           35.7          5.98         1.02 \n  moy_mass var_mass sd_mass se_mass\n     &lt;dbl&gt;    &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;\n1    4043.  120278.    347.    40.6\n2    3369.   72566.    269.    31.5\n3    4680.   79286.    282.    37.0\n4    5485.   98068.    313.    40.1\n5    3527.   81415.    285.    48.9\n6    3939.  131144.    362.    62.1\n\n\n\nVérifiez avec la fonction skim() que les moyennes et écart-types calculés ci-dessus sont corrects.\n\n\npenguins |&gt; \n  filter(!is.na(sex)) |&gt; \n  group_by(species, sex) |&gt; \n  select(flipper_length_mm, body_mass_g) |&gt; \n  skim()\n\nAdding missing grouping variables: `species`, `sex`\n\n\n\nData summary\n\n\nName\nselect(…)\n\n\nNumber of rows\n333\n\n\nNumber of columns\n4\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\nnumeric\n2\n\n\n________________________\n\n\n\nGroup variables\nspecies, sex\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nspecies\nsex\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nflipper_length_mm\nAdelie\nfemale\n0\n1\n187.79\n5.60\n172\n185.00\n188.0\n191.00\n202\n▁▂▇▅▁\n\n\nflipper_length_mm\nAdelie\nmale\n0\n1\n192.41\n6.60\n178\n189.00\n193.0\n197.00\n210\n▃▅▇▃▁\n\n\nflipper_length_mm\nChinstrap\nfemale\n0\n1\n191.74\n5.75\n178\n187.25\n192.0\n195.75\n202\n▂▅▇▇▆\n\n\nflipper_length_mm\nChinstrap\nmale\n0\n1\n199.91\n5.98\n187\n196.00\n200.5\n203.00\n212\n▁▇▅▅▂\n\n\nflipper_length_mm\nGentoo\nfemale\n0\n1\n212.71\n3.90\n203\n210.00\n212.0\n215.00\n222\n▁▇▆▅▂\n\n\nflipper_length_mm\nGentoo\nmale\n0\n1\n221.54\n5.67\n208\n218.00\n221.0\n225.00\n231\n▁▆▇▇▆\n\n\nbody_mass_g\nAdelie\nfemale\n0\n1\n3368.84\n269.38\n2850\n3175.00\n3400.0\n3550.00\n3900\n▅▅▇▅▅\n\n\nbody_mass_g\nAdelie\nmale\n0\n1\n4043.49\n346.81\n3325\n3800.00\n4000.0\n4300.00\n4775\n▃▇▇▇▃\n\n\nbody_mass_g\nChinstrap\nfemale\n0\n1\n3527.21\n285.33\n2700\n3362.50\n3550.0\n3693.75\n4150\n▁▂▇▇▂\n\n\nbody_mass_g\nChinstrap\nmale\n0\n1\n3938.97\n362.14\n3250\n3731.25\n3950.0\n4100.00\n4800\n▃▇▇▂▂\n\n\nbody_mass_g\nGentoo\nfemale\n0\n1\n4679.74\n281.58\n3950\n4462.50\n4700.0\n4875.00\n5200\n▂▅▇▇▃\n\n\nbody_mass_g\nGentoo\nmale\n0\n1\n5484.84\n313.16\n4750\n5300.00\n5500.0\n5700.00\n6300\n▂▆▇▅▂\n\n\n\n\n\n\nAvec ces données synthétiques faites le graphique suivant :\n\n\nresum |&gt; \n  ggplot(aes(x = sex, y = moy_L_nageoire)) +\n  geom_point() +\n  geom_errorbar(aes(ymin = moy_L_nageoire - se_L_nageoire,\n                    ymax = moy_L_nageoire + se_L_nageoire),\n                width = 0.15) +\n  facet_wrap(~species) +\n  labs(x = \"Sexe\",\n       y = \"Longueur des nageoires (mm)\",\n       title = \"Moyennes (et erreurs standard) des longueurs de nageoires\\nchez les mâles et les femelles de trois espèces de manchots\") +\n  theme_bw()"
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Horst, Allison, Alison Hill, and Kristen Gorman. 2022.\nPalmerpenguins: Palmer Archipelago (Antarctica) Penguin Data.\nhttps://CRAN.R-project.org/package=palmerpenguins.\n\n\nWaring, Elin, Michael Quinn, Amelia McNamara, Eduardo Arino de la Rubia,\nHao Zhu, and Shannon Ellis. 2022. Skimr: Compact and Flexible\nSummaries of Data. https://CRAN.R-project.org/package=skimr.\n\n\nWickham, Hadley. 2021. Nycflights13: Flights That Departed NYC in\n2013. https://github.com/hadley/nycflights13.\n\n\n———. 2022. Tidyverse: Easily Install and Load the Tidyverse. https://CRAN.R-project.org/package=tidyverse.\n\n\nWickham, Hadley, Winston Chang, Lionel Henry, Thomas Lin Pedersen,\nKohske Takahashi, Claus Wilke, Kara Woo, Hiroaki Yutani, and Dewey\nDunnington. 2022. Ggplot2: Create Elegant Data Visualisations Using\nthe Grammar of Graphics. https://CRAN.R-project.org/package=ggplot2.\n\n\nWickham, Hadley, Romain François, Lionel Henry, Kirill Müller, and Davis\nVaughan. 2023. Dplyr: A Grammar of Data Manipulation. https://CRAN.R-project.org/package=dplyr.\n\n\nWickham, Hadley, Jim Hester, and Jennifer Bryan. 2022. Readr: Read\nRectangular Text Data. https://CRAN.R-project.org/package=readr."
  },
  {
    "objectID": "01-dispersion.html#pré-requis",
    "href": "01-dispersion.html#pré-requis",
    "title": "1  Exploration statistique des données",
    "section": "1.1 Pré-requis",
    "text": "1.1 Pré-requis\nLa première étape de toute analyse de données est l’exploration. Avant de se lancer dans des tests statistiques et des procédures complexes, et à supposer que les données dont vous disposez sont déjà dans un format approprié, il est toujours très utile :\n\nd’explorer visuellement les données dont on dispose en faisant des graphiques nombreux et variés, afin de comprendre, notamment quelle est la distribution des variables numériques, quelles sont les catégories les plus représentées pour les variables qualitatives (ou facteurs), quelles sont les relations les plus marquantes entre variables numériques et/ou catégorielles, etc. Vous avez déjà appris, au semestre 3, comment produire toutes sortes de graphiques avec le package ggplot2. Si vous avez besoin de revoir les bases, c’est là que ça se passe.\nd’explorer les données en calculant des indices de statistiques descriptives. Ces indices relèvent en général de 2 catégories : les indices de position (e.g. moyennes, médianes, quartiles…) et les indices de dispersion (e.g. variance, écart-type, intervalle inter-quartiles…). Nous allons voir dans ce chapitre comment calculer ces indices dans plusieurs situations, notamment lorsque l’on souhaite les calculer pour plusieurs sous-groupes d’un jeu de données.\n\nNous verrons dans le chapitre suivant comment calculer des indices d’incertitude (Section 2.4 et Section 2.5). Attention, il ne faudra pas confondre indices de dispersion et indices d’incertitude.\nAfin d’explorer ces questions, nous aurons besoin des packages suivants :\n\nlibrary(tidyverse)\nlibrary(skimr)\nlibrary(palmerpenguins)\nlibrary(nycflights13)\n\nLes packages du tidyverse (Wickham 2022) permettent de manipuler facilement des tableaux de données et de réaliser des graphiques. Charger le tidyverse permet d’accéder, entre autres, aux packages readr (Wickham, Hester, et Bryan 2022), pour importer facilement des fichiers .csv au format tibble, dplyr (Wickham et al. 2023) pour manipuler des tableaux de données ou encore ggplot2 (Wickham et al. 2022) pour produire des graphiques. Le package skimr (Waring et al. 2022) permet de calculer des résumés de données très informatifs. Les packages palmerpenguins (Horst, Hill, et Gorman 2022) et nycflights13 (Wickham 2021) fournissent des jeux de données qui seront faciles à manipuler pour illustrer ce chapitre (et les suivants).\n\n\n\n\n\n\nImportant\n\n\n\nMême si vous avez déjà installé le tidyverse ou dplyr au semestre précédent, ré-installez dplyr avec install.packages(\"dplyr\"). Ce package a en effet été mis à jour tout récemment, et nous aurons besoin de sa toute dernière version (v1.1.0). Chargez-le ensuite en mémoire avec library(dplyr).\n\n\n\n\n\n\n\n\nAttention\n\n\n\nPensez à installer tous les packages listés ci-dessous avant de les charger en mémoire si vous ne l’avez pas déjà fait. Si vous ne savez plus comment faire, consultez d’urgence la section dédiée aux packages dans le livre en ligne de Biométrie du semestre 3.\n\n\nPour travailler dans de bonnes conditions, créez un nouveau dossier sur votre ordinateur, créez un Rproject et un script dans ce dossier et travaillez systématiquement dans votre script, et surtout pas directement dans la console. Là encore, consultez le livre en ligne du semestre 3 si vous ne savez plus comment faire."
  },
  {
    "objectID": "01-dispersion.html#créer-des-résumés-avec-la-fonction-summarise",
    "href": "01-dispersion.html#créer-des-résumés-avec-la-fonction-summarise",
    "title": "1  Exploration statistique des données",
    "section": "1.2 Créer des résumés avec la fonction summarise()",
    "text": "1.2 Créer des résumés avec la fonction summarise()\nComme nous l’avons vu au semestre 3, le package dplyr fournit plusieurs fonctions qui portent le nom de verbes et qui permettent d’effectuer des manipulations simples mais qui peuvent devenir très puissantes lorsqu’on les combine. Nous avons ainsi vu les fonctions suivantes :\n\nselect() : pour sélectionner ou exclure certaines colonnes (variables) d’un tableau de données\nfilter() : pour trier des lignes d’un tableau de données selon des critères ou conditions choisis par l’utilisateur\nmutate() : pour transformer des variables existantes, ou pour créer de nouvelles colonnes dans un tableau de données\narrange() : pour trier des tableaux de données par ordre croissants ou décroissants\n\nSi vous ne savez plus comment utiliser ces fonctions, relisez le chapitre 4 du livre en ligne de Biométrie du semestre 3.\nÀ ces 4 verbes, nous allons ici ajouter :\n\nsummarise() : pour créer des résumés de données simples à partir des colonnes d’un tableau\nreframe() : pour créer des résumés de données plus élaborés à partir des colonnes d’un tableau\ncount() : pour compter le nombre d’observations pour chaque niveau d’un facteur (ou modalité d’une variable catégorielle)\ngroup_by() : pour effectuer des opérations pour chaque niveau d’un facteur (ou modalité d’une variable catégorielle)\n\nCette dernière fonction group_by() a été rendue presque obsolète par une mise à jour récente du package dplyr qui introduit un nouvel argument pour plusieurs fonctions, dont summarise() : l’argument .by. Un peu comme group-by(), ce nouvel argument permet d’effectuer des opérations pour chaque niveau d’un facteur (ou modalité d’une variable catégorielle). À notre niveau, les différences entre la fonction group_by() et l’argument .by ne sont pas importantes. Nous utiliserons donc de préférence la notation la plus simple, celle de l’argument .by.\nVoyons comment on utilise ces fonctions pour calculer des indices de statistiques descriptives pour les variables du tableau penguins :\n\n# affichage du tableau\npenguins\n\n# A tibble: 344 × 8\n   species island    bill_length_mm bill_depth_mm flipper_length_mm body_mass_g\n   &lt;fct&gt;   &lt;fct&gt;              &lt;dbl&gt;         &lt;dbl&gt;             &lt;int&gt;       &lt;int&gt;\n 1 Adelie  Torgersen           39.1          18.7               181        3750\n 2 Adelie  Torgersen           39.5          17.4               186        3800\n 3 Adelie  Torgersen           40.3          18                 195        3250\n 4 Adelie  Torgersen           NA            NA                  NA          NA\n 5 Adelie  Torgersen           36.7          19.3               193        3450\n 6 Adelie  Torgersen           39.3          20.6               190        3650\n 7 Adelie  Torgersen           38.9          17.8               181        3625\n 8 Adelie  Torgersen           39.2          19.6               195        4675\n 9 Adelie  Torgersen           34.1          18.1               193        3475\n10 Adelie  Torgersen           42            20.2               190        4250\n# ℹ 334 more rows\n# ℹ 2 more variables: sex &lt;fct&gt;, year &lt;int&gt;\n\n\n\n1.2.1 Principe de la fonction summarise()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 1.1: Schéma de la fonction summarise() tiré de la ‘cheatsheet’ de dplyr et tidyr\n\n\n\n\nLa Figure 1.1 ci-dessus indique comment travaille la fonction summarise() : elle prend plusieurs valeurs (potentiellement, un très grand nombre) et les réduit à une unique valeur qui les résume. La valeur qui résume les données est choisie par l’utilisateur. Il peut s’agir par exemple d’un calcul de moyenne, de quartile ou de variance, il peut s’agir de calculer une somme, ou d’extraire la valeur maximale ou minimale, ou encore, il peut tout simplement s’agir de déterminer un nombre d’observations. Mais le fonctionnement est toujours le même : la fonction summarise() ne renvoie qu’une unique valeur pour une variable donnée (ou pour chaque modalité d’une variable catégorielle).\nAinsi, pour connaître la moyenne de la longueur du bec des manchots de l’île de Palmer, il suffit d’utiliser le tableau penguins du package palmerpenguins et sa variable bill_length_mm que nous avons déjà utilisée au semestre 3 :\n\npenguins |&gt;\n  summarise(moyenne = mean(bill_length_mm))\n\n# A tibble: 1 × 1\n  moyenne\n    &lt;dbl&gt;\n1      NA\n\n\nLa fonction mean() permet de calculer une moyenne. Ici, la valeur retournée est NA car 2 individus n’ont pas été mesurés, et le tableau contient donc des valeurs manquantes :\n\npenguins |&gt;\n  filter(is.na(bill_length_mm))\n\n# A tibble: 2 × 8\n  species island    bill_length_mm bill_depth_mm flipper_length_mm body_mass_g\n  &lt;fct&gt;   &lt;fct&gt;              &lt;dbl&gt;         &lt;dbl&gt;             &lt;int&gt;       &lt;int&gt;\n1 Adelie  Torgersen             NA            NA                NA          NA\n2 Gentoo  Biscoe                NA            NA                NA          NA\n# ℹ 2 more variables: sex &lt;fct&gt;, year &lt;int&gt;\n\n\nPour obtenir la valeur souhaitée, il faut indiquer à R d’exclure les valeurs manquantes lors du calcul de moyenne :\n\npenguins |&gt;\n  summarise(moyenne = mean(bill_length_mm, na.rm = TRUE))\n\n# A tibble: 1 × 1\n  moyenne\n    &lt;dbl&gt;\n1    43.9\n\n\nLa longueur moyenne du bec des manchots (toutes espèces confondues) est donc de 43.9 millimètres.\nDe la même façon, on peut demander plusieurs calculs d’indices à la fois, par exemple la moyenne et l’écart-type (avec la fonction sd()) de la longueur des becs :\n\npenguins |&gt;\n  summarise(moyenne = mean(bill_length_mm, na.rm = TRUE),\n            ecart_type = sd(bill_length_mm, na.rm = TRUE))\n\n# A tibble: 1 × 2\n  moyenne ecart_type\n    &lt;dbl&gt;      &lt;dbl&gt;\n1    43.9       5.46\n\n\nIci, l’écart-type vaut 5.5 millimètres.\nLa fonction summarise() permet donc de calculer des indices statistiques variés, et permet aussi d’accéder à plusieurs variables à la fois. Par exemple. pour calculer les moyennes, médianes, minima et maxima des longueurs de nageoires et de masses corporelles, on peut procéder ainsi :\n\npenguins |&gt; \n  summarise(moy_flip = mean(flipper_length_mm, na.rm = TRUE),\n            med_flip = median(flipper_length_mm, na.rm = TRUE),\n            min_flip = min(flipper_length_mm, na.rm = TRUE),\n            max_flip = max(flipper_length_mm, na.rm = TRUE),\n            moy_mass = mean(body_mass_g, na.rm = TRUE),\n            med_mass = median(body_mass_g, na.rm = TRUE),\n            min_mass = min(body_mass_g, na.rm = TRUE),\n            max_mass = max(body_mass_g, na.rm = TRUE))\n\n# A tibble: 1 × 8\n  moy_flip med_flip min_flip max_flip moy_mass med_mass min_mass max_mass\n     &lt;dbl&gt;    &lt;dbl&gt;    &lt;int&gt;    &lt;int&gt;    &lt;dbl&gt;    &lt;dbl&gt;    &lt;int&gt;    &lt;int&gt;\n1     201.      197      172      231    4202.     4050     2700     6300\n\n\nLa fonction summarise() est donc très utile pour produire des résumés informatifs des données, mais nos exemples ne sont ici pas très pertinents puisque nous avons jusqu’ici calculé des indices sans distinguer les espèces. Si les 3 espèces de manchots ont des caractéristiques très différentes, calculer des moyennes toutes espèces confondues n’a pas de sens. Voyons maintenant comment obtenir ces même indices pour chaque espèce.\n\n\n1.2.2 Intérêt de l’argument .by\nLa fonction summarise() devient particulièrement puissante lorsqu’on y ajoute l’argument .by :\n\n\n\n\n\nFigure 1.2: Fonctionnement de l’argument .by travaillant de concert avec summarise(), tiré de la ‘cheatsheet’ de dplyr et tidyr\n\n\n\n\nComme son nom l’indique, l’argument .by permet de créer des sous-groupes dans un tableau, afin que le résumé des données soit calculé pour chacun des sous-groupes plutôt que sur l’ensemble du tableau. En ce sens, son fonctionnement est analogue à celui des facets de ggplot2 qui permettent de scinder les données d’un graphique en plusieurs sous-groupes.\nPour revenir à l’exemple de la longueur du bec des manchots, imaginons que nous souhaitions calculer les moyennes et les écart-types pour chacune des trois espèces. Voilà comment procéder :\n\npenguins |&gt;\n  summarise(moyenne = mean(bill_length_mm, na.rm = TRUE),\n            ecart_type = sd(bill_length_mm, na.rm = TRUE),\n            .by = species)\n\n# A tibble: 3 × 3\n  species   moyenne ecart_type\n  &lt;fct&gt;       &lt;dbl&gt;      &lt;dbl&gt;\n1 Adelie       38.8       2.66\n2 Gentoo       47.5       3.08\n3 Chinstrap    48.8       3.34\n\n\nIci, les étapes sont les suivantes :\n\nOn prend le tableau penguins, puis\nOn résume les données sous la forme de moyennes et d’écart-types\nOn demande un calcul pour chaque modalité de la variable species\n\nLà où nous avions auparavant une seule valeur de moyenne et d’écart-type pour l’ensemble des individus du tableau de données, nous avons maintenant une valeur de moyenne et d’écart-type pour chaque modalité de la variable espèce. Puisque le facteur species contient 3 modalités (Adelie, Chinstrap et Gentoo), le résumé des données contient maintenant 3 lignes.\nCette syntaxe très simple est presque équivalente à celle de la fonction group_by() :\n\npenguins |&gt;\n  group_by(species) |&gt; \n  summarise(moyenne = mean(bill_length_mm, na.rm = TRUE),\n            ecart_type = sd(bill_length_mm, na.rm = TRUE))\n\n# A tibble: 3 × 3\n  species   moyenne ecart_type\n  &lt;fct&gt;       &lt;dbl&gt;      &lt;dbl&gt;\n1 Adelie       38.8       2.66\n2 Chinstrap    48.8       3.34\n3 Gentoo       47.5       3.08\n\n\nLes valeurs obtenues sont les mêmes, mais d’une part, les commandes sont fournies avec une syntaxe et dans un ordre différents :\n\nOn prend le tableau penguins, puis\nOn groupe les données par espèce, puis\nOn résume les données sous la forme de moyennes et d’écart-types\n\nEt l’objet obtenu au final n’est pas strictement identique : avec la fonction group_by(), et dans certaines situations, la tibble obtenu conserve l’information du regroupement effectué, ce qui peut être utile dans certaines situations, mais pose parfois problème et cause l’affichage de messages d’avertissements dans la console. Ce comportement n’est pas observé avec l’argument .by qui ne groupe les données qu’au moment du calcul des indices dans la fonction summarise() et n’en conserve pas la trace ensuite. C’est la raison pour laquelle nous privilégierons cette méthode.\nPour aller plus loin, ajoutons à ce résumé 2 variables supplémentaires : le nombre de mesures et l’erreur standard (notée \\(se\\)), qui peut être calculée de la façon suivante :\n\\[se \\approx \\frac{s}{\\sqrt{n}}\\]\navec \\(s\\), l’écart-type de l’échantillon et \\(n\\), la taille de l’échantillon (plus d’informations sur cette statistique très importante dans la Chapitre 2). Nous allons donc calculer ici ces résumés, et nous donnerons un nom au tableau créé pour pouvoir ré-utiliser ces statistiques descriptives :\n\nstats_esp &lt;- penguins |&gt;\n  summarise(moyenne = mean(bill_length_mm, na.rm = TRUE),\n            ecart_type = sd(bill_length_mm, na.rm = TRUE),\n            nb_obs = n(),\n            erreur_std = ecart_type / sqrt(nb_obs),\n            .by = species)\n\nstats_esp\n\n# A tibble: 3 × 5\n  species   moyenne ecart_type nb_obs erreur_std\n  &lt;fct&gt;       &lt;dbl&gt;      &lt;dbl&gt;  &lt;int&gt;      &lt;dbl&gt;\n1 Adelie       38.8       2.66    152      0.216\n2 Gentoo       47.5       3.08    124      0.277\n3 Chinstrap    48.8       3.34     68      0.405\n\n\nVous constatez ici que nous avons 4 statistiques descriptives pour chaque espèce. Deux choses sont importantes à retenir ici :\n\non peut obtenir le nombre d’observations dans chaque sous-groupe d’un tableau groupé en utilisant la fonction n(). Cette fonction n’a besoin d’aucun argument : elle détermine automatiquement la taille des groupes créés par .by (ou par la fonction group_by()).\non peut créer de nouvelles variables en utilisant le nom de variables créées auparavant. Ainsi, nous avons créé la variable erreur_std en utilisant deux variables créées au préalable : ecart-type et nb_obs\n\n\n\n1.2.3 Grouper par plus d’une variable\nJusqu’ici, nous avons groupé les données par espèce. Il est tout à fait possible de grouper les données par plus d’une variable, par exemple, par espèce et par sexe :\n\nstats_esp_sex &lt;- penguins |&gt;\n  summarise(moyenne = mean(bill_length_mm, na.rm = TRUE),\n            ecart_type = sd(bill_length_mm, na.rm = TRUE),\n            nb_obs = n(),\n            erreur_std = ecart_type / sqrt(nb_obs),\n            .by = c(species, sex))\n\nstats_esp_sex\n\n# A tibble: 8 × 6\n  species   sex    moyenne ecart_type nb_obs erreur_std\n  &lt;fct&gt;     &lt;fct&gt;    &lt;dbl&gt;      &lt;dbl&gt;  &lt;int&gt;      &lt;dbl&gt;\n1 Adelie    male      40.4       2.28     73      0.267\n2 Adelie    female    37.3       2.03     73      0.237\n3 Adelie    &lt;NA&gt;      37.8       2.80      6      1.14 \n4 Gentoo    female    45.6       2.05     58      0.269\n5 Gentoo    male      49.5       2.72     61      0.348\n6 Gentoo    &lt;NA&gt;      45.6       1.37      5      0.615\n7 Chinstrap female    46.6       3.11     34      0.533\n8 Chinstrap male      51.1       1.56     34      0.268\n\n\nEn plus de la variable species, la tableau stats_esp_sex contient une variable sex. Les statistiques que nous avons calculées plus tôt sont maintenant disponibles pour chaque espèce et chaque sexe. D’ailleurs, puisque le sexe de certains individus est inconnu, nous avons également des lignes pour lesquelles le sexe affiché est NA. Pour les éliminer, il suffit de retirer les lignes du tableau pour lesquelles le sexe des individus est inconnu avant de recalculer les mêmes indices :\n\nstats_esp_sex2 &lt;- penguins |&gt;\n  filter(!is.na(sex)) |&gt; \n  summarise(moyenne = mean(bill_length_mm, na.rm = TRUE),\n            ecart_type = sd(bill_length_mm, na.rm = TRUE),\n            nb_obs = n(),\n            erreur_std = ecart_type / sqrt(nb_obs),\n            .by = c(species, sex))\n\nstats_esp_sex2\n\n# A tibble: 6 × 6\n  species   sex    moyenne ecart_type nb_obs erreur_std\n  &lt;fct&gt;     &lt;fct&gt;    &lt;dbl&gt;      &lt;dbl&gt;  &lt;int&gt;      &lt;dbl&gt;\n1 Adelie    male      40.4       2.28     73      0.267\n2 Adelie    female    37.3       2.03     73      0.237\n3 Gentoo    female    45.6       2.05     58      0.269\n4 Gentoo    male      49.5       2.72     61      0.348\n5 Chinstrap female    46.6       3.11     34      0.533\n6 Chinstrap male      51.1       1.56     34      0.268\n\n\nSi vous ne comprenez pas la commande filter(!is.na(sex)), je vous encourage vivement à consulter cette section du livre en ligne de Biométrie du semestre 3.\nEnfin, lorsque nous groupons par plusieurs variables, il peut être utile de présenter les résultats sous la forme d’un tableau large (grâce à la fonction pivot_wider()) pour l’intégration dans un rapport par exemple. La fonction pivot_wider() permet de passer d’un tableau qui possède ce format :\n\npenguins |&gt;\n  filter(!is.na(sex)) |&gt; \n  summarise(moyenne = mean(bill_length_mm, na.rm = TRUE),\n            .by = c(species, sex))\n\n# A tibble: 6 × 3\n  species   sex    moyenne\n  &lt;fct&gt;     &lt;fct&gt;    &lt;dbl&gt;\n1 Adelie    male      40.4\n2 Adelie    female    37.3\n3 Gentoo    female    45.6\n4 Gentoo    male      49.5\n5 Chinstrap female    46.6\n6 Chinstrap male      51.1\n\n\nà un tableau sous ce format :\n\npenguins |&gt;\n  filter(!is.na(sex)) |&gt; \n  summarise(moyenne = mean(bill_length_mm, na.rm = TRUE),\n            .by = c(species, sex)) |&gt; \n  pivot_wider(names_from = sex,\n              values_from = moyenne)\n\n# A tibble: 3 × 3\n  species    male female\n  &lt;fct&gt;     &lt;dbl&gt;  &lt;dbl&gt;\n1 Adelie     40.4   37.3\n2 Gentoo     49.5   45.6\n3 Chinstrap  51.1   46.6\n\n\nSous cette forme, les données ne sont plus “rangées”, c’est à dire que nous n’avons plus une observation par ligne et une variable par colonne. En effet ici, la variable sex est maintenant “étalée” dans 2 colonnes distinctes : chaque modalité du facteur de départ (female et male) est utilisée en tant que titre de nouvelles colonnes, et la variable moyenne est répartie dans deux colonnes. Ce format de tableau n’est pas idéal pour les statistiques ou les représentations graphiques, mais il est plus synthétique, et donc plus facile à inclure dans un rapport ou un compte-rendu.\n\n\n1.2.4 Un raccourci pratique pour compter des effectifs\nIl est extrêmement fréquent d’avoir à grouper des données en fonction d’une variable catégorielle puis d’avoir à compter le nombre d’observations de chaque modalité avec n() :\n\npenguins |&gt; \n  summarise(effectif = n(), \n            .by = species)\n\n# A tibble: 3 × 2\n  species   effectif\n  &lt;fct&gt;        &lt;int&gt;\n1 Adelie         152\n2 Gentoo         124\n3 Chinstrap       68\n\n\nou encore :\n\npenguins |&gt; \n  group_by(species) |&gt; \n  summarise(effectif = n())\n\n# A tibble: 3 × 2\n  species   effectif\n  &lt;fct&gt;        &lt;int&gt;\n1 Adelie         152\n2 Chinstrap       68\n3 Gentoo         124\n\n\nCes deux opérations sont tellement fréquentes (regrouper puis compter) que le package dplyr nous fournit un raccourci : la fonction count().\nLe code ci-dessus est équivalent à celui-ci :\n\npenguins |&gt; \n  count(species)\n\n# A tibble: 3 × 2\n  species       n\n  &lt;fct&gt;     &lt;int&gt;\n1 Adelie      152\n2 Chinstrap    68\n3 Gentoo      124\n\n\nNotez qu’avec la fonction count(), la colonne qui contient les comptages s’appelle toujours n par défaut. Comme avec .by et group_by(), il est bien sûr possible d’utiliser count() avec plusieurs variables :\n\npenguins |&gt; \n  count(species, sex)\n\n# A tibble: 8 × 3\n  species   sex        n\n  &lt;fct&gt;     &lt;fct&gt;  &lt;int&gt;\n1 Adelie    female    73\n2 Adelie    male      73\n3 Adelie    &lt;NA&gt;       6\n4 Chinstrap female    34\n5 Chinstrap male      34\n6 Gentoo    female    58\n7 Gentoo    male      61\n8 Gentoo    &lt;NA&gt;       5\n\n\n\npenguins |&gt; \n  filter(!is.na(sex)) |&gt; \n  count(species, sex)\n\n# A tibble: 6 × 3\n  species   sex        n\n  &lt;fct&gt;     &lt;fct&gt;  &lt;int&gt;\n1 Adelie    female    73\n2 Adelie    male      73\n3 Chinstrap female    34\n4 Chinstrap male      34\n5 Gentoo    female    58\n6 Gentoo    male      61\n\n\nEt il est évidemment possible de présenter le résultats sous un format de tableau large :\n\npenguins |&gt; \n  filter(!is.na(sex)) |&gt; \n  count(species, sex) |&gt; \n  pivot_wider(names_from = sex,\n              values_from = n)\n\n# A tibble: 3 × 3\n  species   female  male\n  &lt;fct&gt;      &lt;int&gt; &lt;int&gt;\n1 Adelie        73    73\n2 Chinstrap     34    34\n3 Gentoo        58    61\n\n\nVous connaissez maintenant plusieurs méthodes pour calculer à la main des statistiques descriptives pour des variables entières, ou pour des sous-groupes de lignes (par espèce, par sexe, par sexe et par espèce…). Globalement, toutes les fonctions de R qui prennent une série de chiffres en guise d’argument, et qui renvoient une valeur unique, peuvent être utilisées avec la fonction summarise(). En particulier, vous pouvez utiliser les fonctions suivantes pour faire des analyses exploratoires :\n\nmean() : calcul de la moyenne\nmedian() : calcul de la médiane\nmin() : affichage de la valeur minimale\nmax() : affichage de la valeur minimale\nn_distinct() : calcul du nombre de valeurs différentes\nn() : calcul du nombre d’observations\nvar() : calcul de la variance\nsd() : calcul de l’écart-type\nIQR() : calcul de l’intervalle inter-quartiles\n\nEt la liste n’est bien sûr pas exhaustive\n\n\n1.2.5 Exercices\n\nAvec le tableau diamonds du package ggplot2, faites un tableau indiquant combien de diamants de chaque couleur on dispose. Vous devriez obtenir le tableau suivant :\n\n\n\n# A tibble: 7 × 2\n  color     n\n  &lt;ord&gt; &lt;int&gt;\n1 D      6775\n2 E      9797\n3 F      9542\n4 G     11292\n5 H      8304\n6 I      5422\n7 J      2808\n\n\n\nExaminez le tableau weather du package nycflights13 et lisez son fichier d’aide pour comprendre à quoi correspondent les données et comment elles ont été acquises.\nÀ partir du tableau weather faites un tableau indiquant les vitesses de vents minimales, maximales et moyennes, enregistrées chaque mois dans chaque aéroport de New York. Indice : les 3 aéroports de New York sont Newark, LaGuardia Airport et John F. Kennedy, notés respectivement EWR, LGA et JFK dans la variable origin. Votre tableau devrait ressembler à ceci :\n\n\n\n# A tibble: 36 × 5\n   origin month max_wind min_wind moy_wind\n   &lt;chr&gt;  &lt;int&gt;    &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n 1 EWR        1     42.6        0     9.87\n 2 EWR        2   1048.         0    12.2 \n 3 EWR        3     29.9        0    11.6 \n 4 EWR        4     25.3        0     9.63\n 5 EWR        5     33.4        0     8.49\n 6 EWR        6     34.5        0     9.55\n 7 EWR        7     20.7        0     9.15\n 8 EWR        8     21.9        0     7.62\n 9 EWR        9     23.0        0     8.03\n10 EWR       10     26.5        0     8.32\n# ℹ 26 more rows\n\n\n\nSachant que les vitesses du vent sont exprimées en miles par heure, certaines valeurs sont-elles surprenantes ? À l’aide de la fonction filter(), éliminez la ou les valeurs aberrantes. Vous devriez obtenir ce tableau :\n\n\n\n# A tibble: 36 × 5\n   origin month max_wind min_wind moy_wind\n   &lt;chr&gt;  &lt;int&gt;    &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n 1 EWR        1     42.6        0     9.87\n 2 EWR        2     31.1        0    10.7 \n 3 EWR        3     29.9        0    11.6 \n 4 EWR        4     25.3        0     9.63\n 5 EWR        5     33.4        0     8.49\n 6 EWR        6     34.5        0     9.55\n 7 EWR        7     20.7        0     9.15\n 8 EWR        8     21.9        0     7.62\n 9 EWR        9     23.0        0     8.03\n10 EWR       10     26.5        0     8.32\n# ℹ 26 more rows\n\n\n\nEn utilisant les données de vitesse de vent du tableau weather, produisez le graphique suivant :\n\n\n\n\n\n\nIndications :\n\nles vitesses de vent aberrantes ont été éliminées grâce à la fonction filter()\nla fonction geom_jitter() a été utilisée avec l’argument height = 0\nla transparence des points est fixée à 0.2\n\n\nÀ votre avis :\n\n\npourquoi les points sont-ils organisés en bandes horizontales ?\npourquoi n’y a-t-il jamais de vent entre 0 et environ 3 miles à l’heure (mph) ?\nSachant qu’en divisant des mph par 1.151 on obtient des vitesses en nœuds, que nous apprend cette commande :\n\n\nsort(unique(weather$wind_speed)) / 1.151\n\n [1]   0.000000   2.999427   3.999235   4.999044   5.998853   6.998662\n [7]   7.998471   8.998280   9.998089  10.997897  11.997706  12.997515\n[13]  13.997324  14.997133  15.996942  16.996751  17.996560  18.996368\n[19]  19.996177  20.995986  21.995795  22.995604  23.995413  24.995222\n[25]  25.995030  26.994839  27.994648  28.994457  29.994266  30.994075\n[31]  31.993884  32.993692  33.993501  34.993310  36.992928 910.825873"
  },
  {
    "objectID": "01-dispersion.html#sec-pivot",
    "href": "01-dispersion.html#sec-pivot",
    "title": "1  Exploration statistique des données",
    "section": "1.3 Les fonctions pivot_wider() et pivot_longer()",
    "text": "1.3 Les fonctions pivot_wider() et pivot_longer()\n\n1.3.1 Du format long au format large : pivot_wider()\nComme nous venons de le voir, la fonction pivot_wider() permet de passer d’un tableau au format long à un tableau au format large, qui contient donc moins de lignes mais plus de colonnes.\nPar exemple, lorsque l’on dispose d’un tableau contenant un résumé de données pour plusieurs catégories et sous-catégories, il peut être utile de le transformer au format large pour l’intégrer dans un rapport (la présentation en est ainsi plus synthétique) ou pour faire certains types de graphiques. Par exemple, avec ce tableau de résumé de données :\n\nresum &lt;- penguins |&gt; \n  filter(!is.na(sex)) |&gt; \n  count(species, sex)\n\nresum\n\n# A tibble: 6 × 3\n  species   sex        n\n  &lt;fct&gt;     &lt;fct&gt;  &lt;int&gt;\n1 Adelie    female    73\n2 Adelie    male      73\n3 Chinstrap female    34\n4 Chinstrap male      34\n5 Gentoo    female    58\n6 Gentoo    male      61\n\n\nLa présentation au format large serait plus appropriée dans un compte-rendu de TP :\n\nresum_large1 &lt;- resum |&gt; \n  pivot_wider(names_from = sex,\n              values_from = n)\n\nresum_large1\n\n# A tibble: 3 × 3\n  species   female  male\n  &lt;fct&gt;      &lt;int&gt; &lt;int&gt;\n1 Adelie        73    73\n2 Chinstrap     34    34\n3 Gentoo        58    61\n\n\nL’argument names_from permet d’indiquer dans quelle colonne du tableau de départ aller cherche les noms de colonnes pour le nouveau tableau. Ici, on va chercher dans la colonne sex les noms de colonne du futur tableau (female et male). L’argument values_from permet d’indiquer dans quelle colonne du tableau de départ on souhaite aller chercher les valeurs que l’on souhaite mettre dans les nouvelles colonnes du futur tableau (ici, les effectifs stockés dans la colonne n).\nLe terme “tableau large” peut-être trompeur car le tableau obtenu n’a pas forcément plus de colonnes que le tableau d’origine. En tous cas, il a toujours moins de lignes que le tableau de départ. Ici, resum avait 6 lignes et 3 colonnes, resum_large1 possède 3 lignes et 3 colonnes.\nSi on souhaite avoir les espèces en colonnes et les sexes en lignes, on peut taper ceci :\n\nresum_large2 &lt;- resum |&gt; \n  pivot_wider(names_from = species, \n              values_from = n)\n\nresum_large2\n\n# A tibble: 2 × 4\n  sex    Adelie Chinstrap Gentoo\n  &lt;fct&gt;   &lt;int&gt;     &lt;int&gt;  &lt;int&gt;\n1 female     73        34     58\n2 male       73        34     61\n\n\nCette fois, resum_large2 possède 2 lignes et 4 colonnes. Le caractère “large” de ce nouveau tableau est ici bien apparent. Notez bien que ce sont toujours les mêmes données qui figurent dans ces 3 objets : seule la présentation change.\n\n\n1.3.2 Du format large au format long : pivot_longer()\nÀ l’inverse, on dispose parfois de données au format large alors que la plupart des fonctions graphiques et statistiques de R requièrent des données au format long, c’est à dire, des tableaux dans lesquels il y a une correspondance stricte entre colonnes et variables : une variable est contenue dans une seule colonne d’un tableau, et chaque ligne correspond à une unique observation. AInsi, le tableau resum_large2 n’est pas au format long :\n\nresum_large2\n\n# A tibble: 2 × 4\n  sex    Adelie Chinstrap Gentoo\n  &lt;fct&gt;   &lt;int&gt;     &lt;int&gt;  &lt;int&gt;\n1 female     73        34     58\n2 male       73        34     61\n\n\nEn effet, 3 de ses colonnes contiennent des données d’abondances qui pourraient (ou devraient) se trouver dans une unique colonne Abondance, et le titre de ces 3 colonnes devrait être les catégories d’une autre variable Espece. Pour transformer un tableau large en tableau long (qui contient donc toujours plus de lignes, et souvent moins de colonnes), on utilise pivot_longer(). Cette fonction possède 3 arguments :\n\ncols : quelles sont les colonnes que l’on souhaite regrouper\nnames_to : comment s’appellera la variable qui contiendra les anciens noms de colonnes du tableau large\nvalues_to : comment s’appellera la variable qui contiendra les données contenues dans les cellules du tableau large\n\nVoilà un exemple :\n\nresum_long &lt;- resum_large2 |&gt; \n  pivot_longer(cols = c(Adelie, Chinstrap, Gentoo),\n               names_to = \"Espece\",\n               values_to = \"Abondance\")\n\nresum_long\n\n# A tibble: 6 × 3\n  sex    Espece    Abondance\n  &lt;fct&gt;  &lt;chr&gt;         &lt;int&gt;\n1 female Adelie           73\n2 female Chinstrap        34\n3 female Gentoo           58\n4 male   Adelie           73\n5 male   Chinstrap        34\n6 male   Gentoo           61\n\n\nLes 3 colonnes qui contenaient les abondance des 3 espèces de manchots ont été regroupées en 2 nouvelles colonnes dont les noms ont été précisés grâce à names_to et values_to.\nIl est très fréquent d’avoir à passer d’un format large à un format long ou inversement. Il est donc important que vous appreniez à vous familiariser avec ces 2 fonctions.\n\n\n\n\n\n\nles tableaux rangés\n\n\n\nLa plupart des fonctions du tidyverse supposent que les tableaux soient rangés (une colonne par variable, une ligne par observation) et qu’ils aient donc un format long. À l’inverse, pour présenter des tableaux dans un rapport ou pour certaines méthodes particulières, les données peuvent être présentées au format large. Les fonctions pivot_wider() et pivot_longer() sont complémentaires et permettent de passer d’un format à l’autre."
  },
  {
    "objectID": "01-dispersion.html#créer-des-résumés-avec-la-fonction-reframe",
    "href": "01-dispersion.html#créer-des-résumés-avec-la-fonction-reframe",
    "title": "1  Exploration statistique des données",
    "section": "1.4 Créer des résumés avec la fonction reframe()",
    "text": "1.4 Créer des résumés avec la fonction reframe()\nComme nous venons de le voir, les calculs que nous pouvons faire grâce à la fonction summarise() impliquent des fonctions statistiques qui ne renvoient qu’une valeur à la fois lorsqu’on leur fournit une série de valeurs. Par exemple, si on dispose d’un vecteur numérique (les entiers compris entre 1 et 100 pour l’exemple) :\n\n1:100\n\n  [1]   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17  18\n [19]  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35  36\n [37]  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53  54\n [55]  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71  72\n [73]  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89  90\n [91]  91  92  93  94  95  96  97  98  99 100\n\n\nla fonction mean() ne renvoie qu’une valeur, la moyenne des 100 valeurs contenues dans le vecteur :\n\nmean(1:100)\n\n[1] 50.5\n\n\nDe même pour les fonctions sd(), ou median(), ou toutes les autres fonctions listées à la fin de la Section 1.2.4 :\n\nsd(1:100)\n\n[1] 29.01149\n\nmedian(1:100)\n\n[1] 50.5\n\n\nIl existe toutefois des fonctions qui renvoient plus d’une valeur à la fois. Par exemple, la fonction quantile(), renvoie par défaut 5 éléments :\n\nla valeur minimale contenue dans le vecteur (ou quantile 0%) : c’est la valeur la plus faible contenue dans la série de données\nle premier quartile du vecteur (Q1 ou quantile 25%) est la valeur coupant l’échantillon en deux : 25% des observations du vecteur y sont inférieures et 75% y sont supérieures\nla médiane du vecteur (Q2 ou quantile 50%) est la valeur coupant l’échantillon en deux : 50% des observations du vecteur sont inférieures à cette valeur et 50% y sont supérieures\nle troisième quartile du vecteur (Q3 ou quantile 75%) est la valeur coupant l’échantillon en deux : 75% des observations du vecteur y sont inférieures et 25% y sont supérieures\nla valeur maximale contenue dans le vecteur (ou quantile 100%) : c’est la valeur la plus élevée contenue dans la série de données.\n\nPar exemple, toujours avec le vecteur des entiers contenus entre 1 et 100 :\n\nquantile(1:100)\n\n    0%    25%    50%    75%   100% \n  1.00  25.75  50.50  75.25 100.00 \n\n\nL’objet obtenu est un vecteur dont chaque élément porte un nom. Pour transformer cet objet en tibble, on utilise la fonction enframe() :\n\nenframe(quantile(1:100))\n\n# A tibble: 5 × 2\n  name  value\n  &lt;chr&gt; &lt;dbl&gt;\n1 0%      1  \n2 25%    25.8\n3 50%    50.5\n4 75%    75.2\n5 100%  100  \n\n\nIl peut être très utile de calculer ces différentes valeurs pour plusieurs variables à la fois, ou pour plusieurs sous-groupes d’un jeu de données. Le problème est que nous ne pouvons pas utiliser summarise() car la fonction quantile() ne renvoie pas qu’une unique valeur. Par exemple, pour calculer les quantiles des longueurs de becs pour chaque espèce de manchots, on pourrait être tenté de taper ceci :\n\npenguins |&gt; \n  summarise(Indices = quantile(bill_length_mm, na.rm = TRUE), \n            .by = species)\n\nWarning: Returning more (or less) than 1 row per `summarise()` group was deprecated in\ndplyr 1.1.0.\nℹ Please use `reframe()` instead.\nℹ When switching from `summarise()` to `reframe()`, remember that `reframe()`\n  always returns an ungrouped data frame and adjust accordingly.\n\n\n# A tibble: 15 × 2\n   species   Indices\n   &lt;fct&gt;       &lt;dbl&gt;\n 1 Adelie       32.1\n 2 Adelie       36.8\n 3 Adelie       38.8\n 4 Adelie       40.8\n 5 Adelie       46  \n 6 Gentoo       40.9\n 7 Gentoo       45.3\n 8 Gentoo       47.3\n 9 Gentoo       49.6\n10 Gentoo       59.6\n11 Chinstrap    40.9\n12 Chinstrap    46.3\n13 Chinstrap    49.6\n14 Chinstrap    51.1\n15 Chinstrap    58  \n\n\nC’est dans ces situations que la fonction reframe() est utile. Elle joue le même rôle que summarise(), mais dans les situation où les fonctions statistiques renvoient plus d’une valeur à la fois :\n\npenguins |&gt; \n  reframe(Indices = quantile(bill_length_mm, na.rm = TRUE), \n          .by = species)\n\n# A tibble: 15 × 2\n   species   Indices\n   &lt;fct&gt;       &lt;dbl&gt;\n 1 Adelie       32.1\n 2 Adelie       36.8\n 3 Adelie       38.8\n 4 Adelie       40.8\n 5 Adelie       46  \n 6 Gentoo       40.9\n 7 Gentoo       45.3\n 8 Gentoo       47.3\n 9 Gentoo       49.6\n10 Gentoo       59.6\n11 Chinstrap    40.9\n12 Chinstrap    46.3\n13 Chinstrap    49.6\n14 Chinstrap    51.1\n15 Chinstrap    58  \n\n\nAu contraire de summarise(), reframe() ne renvoie pas de message d’avertissement dans cette situation. Dans cet exemple, on ne sait malheureusement pas à quoi correspondent les chiffres renvoyés puisque l’information des quartiles a disparu (quelles valeurs correspondent aux médianes ou aux premiers quartiles par exemple). Pour y remédier, on doit transformer le vecteur renvoyé par quantile() en tibble. Nous avons déjà vu comment le faire grâce à la fonction enframe(). Par ailleurs, puisque la fonction va maintenant renvoyer un tableau, on n’a pas besoin de lui fournir de nom de colonnes (je retire donc Indices = de mon code) :\n\npenguins |&gt; \n  reframe(enframe(quantile(bill_length_mm, na.rm = TRUE)), \n          .by = species)\n\n# A tibble: 15 × 3\n   species   name  value\n   &lt;fct&gt;     &lt;chr&gt; &lt;dbl&gt;\n 1 Adelie    0%     32.1\n 2 Adelie    25%    36.8\n 3 Adelie    50%    38.8\n 4 Adelie    75%    40.8\n 5 Adelie    100%   46  \n 6 Gentoo    0%     40.9\n 7 Gentoo    25%    45.3\n 8 Gentoo    50%    47.3\n 9 Gentoo    75%    49.6\n10 Gentoo    100%   59.6\n11 Chinstrap 0%     40.9\n12 Chinstrap 25%    46.3\n13 Chinstrap 50%    49.6\n14 Chinstrap 75%    51.1\n15 Chinstrap 100%   58  \n\n\nEnfin, comme précédemment, il est possible de modifier la forme de ce tableau (avec pivot_wider()) pour le lire plus facilement et éventuellement l’intégrer dans un rapport ou compte-rendu :\n\npenguins |&gt;\n  reframe(enframe(quantile(bill_length_mm, na.rm = TRUE)), \n          .by = species) |&gt; \n  pivot_wider(names_from = species,\n              values_from = value)\n\n# A tibble: 5 × 4\n  name  Adelie Gentoo Chinstrap\n  &lt;chr&gt;  &lt;dbl&gt;  &lt;dbl&gt;     &lt;dbl&gt;\n1 0%      32.1   40.9      40.9\n2 25%     36.8   45.3      46.3\n3 50%     38.8   47.3      49.6\n4 75%     40.8   49.6      51.1\n5 100%    46     59.6      58  \n\n\nCes statistiques nous permettent de constater que les manchots de l’espèce Adélie semblent avoir des becs plus courts que les 2 autres espèces (les 5 quantiles le confirment). Les manchots Gentoo et Chinstrap ont en revanche des becs de longueur à peu près similaires, bien que ceux des Chinstrap soient peut-être très légèrement plus longs (Q1, médiane et Q3 supérieurs à ceux des Gentoo). On peut vérifier tout ça graphiquement avec des boîtes à moustaches :\n\npenguins |&gt; \n  ggplot(aes(x = species, y = bill_length_mm)) +\n  geom_boxplot() +\n  labs(x = \"Espèce\", y = \"Longueur du bec (mm)\") +\n  theme_bw()\n\nWarning: Removed 2 rows containing non-finite values (`stat_boxplot()`).\n\n\n\n\n\nOu avec un graphique de densité :\n\npenguins |&gt; \n  ggplot(aes(x = bill_length_mm, fill = species)) +\n  geom_density(alpha = 0.5, show.legend = FALSE) +\n  geom_rug() +\n  labs(x = \"Longueur du bec (mm)\", y = \"Densité\") +\n  facet_wrap(~species, ncol = 1) +\n  scale_fill_brewer(palette = \"Accent\") +\n  theme_bw()\n\nWarning: Removed 2 rows containing non-finite values (`stat_density()`).\n\n\n\n\n\nÀ ce stade, vous devriez être capables de créer (et d’interpréter !) ce type de graphiques. Si ce n’est pas le cas, consultez d’urgence le chapitre 3 du livre en ligne de Biométrie du semestre 3.\n\n\n\n\n\n\nÀ retenir\n\n\n\n\nla fonction summarise() s’utilise avec des fonctions statistiques qui ne renvoient qu’une valeur (par exemple mean(), median(), sd(), var()…)\nla fonction reframe() s’utilise avec des fonctions statistiques qui renvoient plusieurs valeurs (par exemple quantile(), range()…)"
  },
  {
    "objectID": "01-dispersion.html#créer-des-résumés-de-données-avec-des-fonctions-spécifiques",
    "href": "01-dispersion.html#créer-des-résumés-de-données-avec-des-fonctions-spécifiques",
    "title": "1  Exploration statistique des données",
    "section": "1.5 Créer des résumés de données avec des fonctions spécifiques",
    "text": "1.5 Créer des résumés de données avec des fonctions spécifiques\nLes fonctions summarise() et reframe(), avec leur argument .by() (ou la fonction group_by()) permettent donc de calculer n’importe quel indice de statistique descriptive sur un tableau de données entier ou sur des modalités ou combinaisons de modalités de facteurs. Il existe par ailleurs de nombreuses fonctions, disponibles de base dans R ou dans certains packages spécifiques, qui permettent de fournir des résumés plus ou moins automatiques de tout ou partie des variables d’un jeu de données. Nous allons en décrire 2 ici, mais il en existe beaucoup d’autres : à vous d’explorer les possibilités et d’utiliser les fonctions qui vous paraissent les plus pertinentes, les plus simples à utiliser, les plus visuelles ou les plus complètes.\n\n1.5.1 La fonction summary()\nLa fonction summary() (à ne pas confondre avec summarise()) permet d’obtenir des résumés de données pour tous types d’objets dans R. Selon la classe des objets que l’on transmets à summary(), la nature des résultats obtenus changera. Nous verrons ainsi au semestre 6 que cette fonction peut être utilisée pour examiner les résultats de modèles de régressions linéaires ou d’analyses de variances. Pour l’instant, nous nous intéressons à 3 situations :\n\nce que renvoie la fonction quand on lui fournit un vecteur\nce que renvoie la fonction quand on lui fournit un facteur\nce que renvoie la fonction quand on lui fournit un tableau\n\n\n1.5.1.1 Variable continue : vecteur numérique\nCommençons par fournir un vecteur numérique à la fonction summary(). Nous allons pour cela extraire les données de masses corporelles des manchots du tableau penguins :\n\npenguins$body_mass_g\n\n  [1] 3750 3800 3250   NA 3450 3650 3625 4675 3475 4250 3300 3700 3200 3800 4400\n [16] 3700 3450 4500 3325 4200 3400 3600 3800 3950 3800 3800 3550 3200 3150 3950\n [31] 3250 3900 3300 3900 3325 4150 3950 3550 3300 4650 3150 3900 3100 4400 3000\n [46] 4600 3425 2975 3450 4150 3500 4300 3450 4050 2900 3700 3550 3800 2850 3750\n [61] 3150 4400 3600 4050 2850 3950 3350 4100 3050 4450 3600 3900 3550 4150 3700\n [76] 4250 3700 3900 3550 4000 3200 4700 3800 4200 3350 3550 3800 3500 3950 3600\n [91] 3550 4300 3400 4450 3300 4300 3700 4350 2900 4100 3725 4725 3075 4250 2925\n[106] 3550 3750 3900 3175 4775 3825 4600 3200 4275 3900 4075 2900 3775 3350 3325\n[121] 3150 3500 3450 3875 3050 4000 3275 4300 3050 4000 3325 3500 3500 4475 3425\n[136] 3900 3175 3975 3400 4250 3400 3475 3050 3725 3000 3650 4250 3475 3450 3750\n[151] 3700 4000 4500 5700 4450 5700 5400 4550 4800 5200 4400 5150 4650 5550 4650\n[166] 5850 4200 5850 4150 6300 4800 5350 5700 5000 4400 5050 5000 5100 4100 5650\n[181] 4600 5550 5250 4700 5050 6050 5150 5400 4950 5250 4350 5350 3950 5700 4300\n[196] 4750 5550 4900 4200 5400 5100 5300 4850 5300 4400 5000 4900 5050 4300 5000\n[211] 4450 5550 4200 5300 4400 5650 4700 5700 4650 5800 4700 5550 4750 5000 5100\n[226] 5200 4700 5800 4600 6000 4750 5950 4625 5450 4725 5350 4750 5600 4600 5300\n[241] 4875 5550 4950 5400 4750 5650 4850 5200 4925 4875 4625 5250 4850 5600 4975\n[256] 5500 4725 5500 4700 5500 4575 5500 5000 5950 4650 5500 4375 5850 4875 6000\n[271] 4925   NA 4850 5750 5200 5400 3500 3900 3650 3525 3725 3950 3250 3750 4150\n[286] 3700 3800 3775 3700 4050 3575 4050 3300 3700 3450 4400 3600 3400 2900 3800\n[301] 3300 4150 3400 3800 3700 4550 3200 4300 3350 4100 3600 3900 3850 4800 2700\n[316] 4500 3950 3650 3550 3500 3675 4450 3400 4300 3250 3675 3325 3950 3600 4050\n[331] 3350 3450 3250 4050 3800 3525 3950 3650 3650 4000 3400 3775 4100 3775\n\n\nNous avons donc 344 valeurs de masses en grammes qui correspondent aux 344 manchots du jeu de données. La fonction summary() renvoie le résumé suivant lorsqu’on lui fournit ces valeurs :\n\nsummary(penguins$body_mass_g)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's \n   2700    3550    4050    4202    4750    6300       2 \n\n\nNous obtenons ici 7 valeurs, qui correspondent respectivement à :\n\nla valeur minimale observée dans le vecteur. Ici, le manchot le plus léger de l’échantillon pèse donc 2700 grammes.\nla valeur du premier quartile du vecteur. Le premier quartile est la valeur qui coupe l’échantillon en 2 groupes : 25% des observations du vecteur sont inférieures au premier quartile, et 75% des observations du vecteur sont supérieures au premier quartile. Ici, 25% des manchots de l’échantillon (soit 86 individus) ont une masse inférieure à 3550 grammes, et 75% des individus de l’échantillon (soit 258 individus) ont une masse supérieure à 3550 grammes.\nla valeur de médiane du vecteur. La médiane est la valeur qui coupe l’échantillon en 2 groupes : 50% des observations du vecteur sont inférieures à la médiane, et 50% des observations du vecteur sont supérieures à la médiane. Ici, 50% des manchots de l’échantillon (soit 172 individus) ont une masse inférieure à 4050 grammes, et 50% des individus de l’échantillon (soit 172 individus) ont une masse supérieure à 4050 grammes.\nla moyenne du vecteur. Ici, les manchots des 3 espèces du jeu de données ont en moyenne une masse 4202 grammes.\nla valeur du troisième quartile du vecteur. Le troisième quartile est la valeur qui coupe l’échantillon en 2 groupes : 75% des observations du vecteur sont inférieures au troisième quartile, et 25% des observations du vecteur sont supérieures au troisième quartile. Ici, 75% des manchots de l’échantillon (soit 258 individus) ont une masse inférieure à 4700 grammes, et 25% des individus de l’échantillon (soit 86 individus) ont une masse supérieure à 4750 grammes.\nla valeur maximale observée dans le vecteur. Ici, le manchot le plus lourd de l’échantillon pèse donc 6300 grammes.\nle nombre de données manquantes. Ici, 2 manchots n’ont pas été pesés et présentent donc la mention NA (comme Not Available) pour la variable body_mass_g.\n\nCette fonction fournit donc 2 indices de plus que la fonction quantile() (la moyenne et le nombre de valeurs manquantes) :\n\nquantile(penguins$body_mass_g, na.rm = TRUE)\n\n  0%  25%  50%  75% 100% \n2700 3550 4050 4750 6300 \n\n\nMais contrairement à ce que nous avons vu plus haut, la fonction summary() ne possède pas d’argument .by() et il n’est pas possible de l’utiliser avec la fonction group_by(). Par conséquent, il n’est pas possible de se servir de cette fonction pour avoir des valeurs pour chaque modalités d’un facteur (pour chaque espèce par exemple).\nLes différents indices statistiques fournis nous renseignent à la fois sur la position de la distribution et sur la dispersion des données.\n\nLa position correspond à la tendance centrale et indique quelles sont les valeurs qui caractérisent le plus grand nombre d’individus. La moyenne et la médiane sont les deux indices de position les plus fréquemment utilisés. Lorsqu’une variable a une distribution parfaitement symétrique, la moyenne et la médiane sont strictement égales. Mais lorsqu’une distribution est asymétrique, la moyenne et la médiane diffèrent. En particulier, la moyenne est beaucoup plus sensible aux valeurs extrêmes que la médiane. Cela signifie que quand une distribution est très asymétrique, la médiane est souvent une meilleure indication des valeurs les plus fréquemment observées.\n\n\n\n\n\n\nFigure 1.3: Distribution des masses corporelles des manchots\n\n\n\n\nL’histogramme de la Figure 1.3 montre la distribution de la taille des manchots (toutes espèces confondues). Cette distribution présente une asymétrie à droite. Cela signifie que la distribution n’est pas symétrique et que la “queue de distribution” est plus longue à droite qu’à gauche. La plupart des individus ont une masse comprise entre 3500 et 3700 grammes, au niveau du pic principal du graphique. La médiane, en orange et qui vaut 4050 grammes est plus proche du pic que la moyenne, en rouge, qui vaut 4202 grammes. Ici, la différence entre moyenne et médiane n’est pas énorme, mais elle peut le devenir si la distribution est vraiment très asymétrique, par exemple, si quelques individus seulement avaient une masse supérieure à 7000 grammes, la moyenne serait tirée vers la droite du graphique alors que la médiane ne serait presque pas affectée. La moyenne représenterait alors encore moins fidèlement la tendance centrale.\nSi l’on revient à la fonction summary(), observer des valeurs proches pour la moyenne et la médiane nous indique donc le degré de symétrie de la distribution.\n\nLa dispersion des données nous renseigne sur la dispersion des points autour des indices de position. Les quartiles et les valeurs minimales et maximales renvoyées par la fonction summary() nous renseignent sur l’étalement des points. Les valeurs situées entre le premier et le troisième quartile correspondent aux 50% des valeurs de l’échantillon les plus centrales. Plus l’étendue entre ces quartiles (notée IQR pour “intervalle interquartile”) sera grande, plus la dispersion sera importante. D’ailleurs, lorsque la dispersion est très importante, les moyennes et médianes ne renseignent que très moyennement sur la tendance centrale. Les indices de position sont surtout pertinents lorsque la dispersion des points autour de cette tendance centrale n’est pas trop large. Par exemple, si la distribution des données ressemblait à ceci (Figure 1.4), la moyenne et la médiane seraient fort peu utiles car très éloignées de la plupart des observations :\n\n\n\n\n\n\nFigure 1.4: Distribution des masses corporelles (données fictives)\n\n\n\n\nOn comprend donc l’importance de considérer les indices de dispersion en plus des indices de position pour caractériser et comprendre une série de données numériques. L’intervalle interquartile est toujours utile pour connaître l’étendue des données qui correspondent aux 50% des observations les plus centrales. Les autres indices de dispersion très fréquemment utilisés, mais qui ne sont pas proposés par défaut par la fonction summary(), sont la variance et l’écart-type. Il est possible de calculer tous les indices renvoyés par la fonction summary() et ceux qui nous manquent grâce à la fonction summarise() :\n\npenguins |&gt; \n  summarise(min = min(body_mass_g, na.rm = TRUE),\n            Q1 = quantile(body_mass_g, 0.25, na.rm = TRUE),\n            med = median(body_mass_g, na.rm = TRUE),\n            moy = mean(body_mass_g, na.rm = TRUE),\n            Q3 = quantile(body_mass_g, 0.75, na.rm = TRUE),\n            max = max(body_mass_g, na.rm = TRUE),\n            var = var(body_mass_g, na.rm = TRUE),\n            et = sd(body_mass_g, na.rm = TRUE))\n\n# A tibble: 1 × 8\n    min    Q1   med   moy    Q3   max     var    et\n  &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;dbl&gt;\n1  2700  3550  4050 4202.  4750  6300 643131.  802.\n\n\nVous notez que le code est beaucoup plus long, et qu’utiliser summary() peut donc faire gagner beaucoup de temps, même si cette fonction ne nous fournit ni la variance ni l’écart-type. Mais comme souvent dans R, il est possible de calculer à la main toutes ces valeurs si besoin. Comme indiqué plus haut, les fonctions suivantes peuvent être utilisées :\n\nmean() permet de calculer la moyenne.\nmedian() permet de calculer la médiane.\nmin() et max() permettent de calculer les valeurs minimales et maximales respectivement.\nquantile() permet de calculer les quartiles. Vous notez que contrairement aux exemples de la partie précédente, on utilise ici la fonction quantile() en précisant une valeur supplémentaire pour n’obtenir qu’une valeur à la fois : 0.25 pour le premier quartile, et 0.75 pour le troisième.\nsd() permet de calculer l’écart-type.\nvar() permet de calculer la variance.\n\nPour toutes ces fonctions l’argument na.rm = TRUE permet d’obtenir les résultats même si certaines valeurs sont manquantes. Enfin, la fonction IQR() permet de calculer l’intervalle inter-quartiles :\n\nIQR(penguins$body_mass_g, na.rm = TRUE)\n\n[1] 1200\n\n\nIci, les 50% des valeurs les plus centrales de l’échantillon sont situées dans un intervalle de 1200 grammes autour de la médiane.\n\n\n1.5.1.2 Variable quantitative : facteur\nSi l’on fournit une variable catégorielle ou facteur à summary(), le résultat obtenu sera naturellement différent : calculer des moyennes, médianes ou quartiles n’aurait en effet pas de sens lorsque la variable fournie ne contient que des catégories :\n\nsummary(penguins$species)\n\n   Adelie Chinstrap    Gentoo \n      152        68       124 \n\n\nPour les facteurs, summary() compte simplement le nombre d’observations pour chaque modalité. Ici, la variable species est un facteur qui compte 3 modalités. La fonction summary() nous indique donc le nombre d’individus pour chaque modalité : notre jeu de données se compose de 152 individus de l’espèce Adélie, 68 individus de l’espèce Chinstrap, et 124 individus de l’espèce Gentoo.\nComme pour les vecteurs numériques, si le facteur présente des données manquantes, la fonction summary() compte également leur nombre :\n\nsummary(penguins$sex)\n\nfemale   male   NA's \n   165    168     11 \n\n\nPour les facteurs, la fonction summary() est donc tout à fait équivalente à la fonction count() :\n\npenguins |&gt; \n  count(species)\n\n# A tibble: 3 × 2\n  species       n\n  &lt;fct&gt;     &lt;int&gt;\n1 Adelie      152\n2 Chinstrap    68\n3 Gentoo      124\n\n\nL’avantage de la fonction count() est qu’il est possible d’utiliser plusieurs facteurs pour compter le nombre d’observations de toutes les combinaisons de modalités (par exemple, combien d’individus de chaque sexe pour chaque espèce), ce qui n’est pas possible avec la fonction summary().\n\n\n1.5.1.3 Les tableaux : data.frame ou tibble\nL’avantage de la fonction summary() par rapport à la fonction count() apparaît lorsque l’on souhaite obtenir des informations sur toutes les variables d’un tableau à la fois :\n\nsummary(penguins)\n\n      species          island    bill_length_mm  bill_depth_mm  \n Adelie   :152   Biscoe   :168   Min.   :32.10   Min.   :13.10  \n Chinstrap: 68   Dream    :124   1st Qu.:39.23   1st Qu.:15.60  \n Gentoo   :124   Torgersen: 52   Median :44.45   Median :17.30  \n                                 Mean   :43.92   Mean   :17.15  \n                                 3rd Qu.:48.50   3rd Qu.:18.70  \n                                 Max.   :59.60   Max.   :21.50  \n                                 NA's   :2       NA's   :2      \n flipper_length_mm  body_mass_g       sex           year     \n Min.   :172.0     Min.   :2700   female:165   Min.   :2007  \n 1st Qu.:190.0     1st Qu.:3550   male  :168   1st Qu.:2007  \n Median :197.0     Median :4050   NA's  : 11   Median :2008  \n Mean   :200.9     Mean   :4202                Mean   :2008  \n 3rd Qu.:213.0     3rd Qu.:4750                3rd Qu.:2009  \n Max.   :231.0     Max.   :6300                Max.   :2009  \n NA's   :2         NA's   :2                                 \n\n\nIci, on obtient un résumé pour chaque colonne du tableau. Les colonnes numériques sont traitées comme les vecteurs numériques (on obtient alors les minimas et maximas, les quartiles, les moyennes et médianes) et les colonnes contenant des variables catégorielles sont traitées comme des facteurs (et on obtient alors le nombre d’observations pour chaque modalité).\nOn constate au passage que la variable year est considérée ici comme une variable numérique, alors qu’elle devrait plutôt être considérée comme un facteur, ce qui nous permettrait de savoir combien d’individus ont été échantillonnés chaque année :\n\npenguins |&gt; \n  mutate(year = factor(year)) |&gt; \n  summary()\n\n      species          island    bill_length_mm  bill_depth_mm  \n Adelie   :152   Biscoe   :168   Min.   :32.10   Min.   :13.10  \n Chinstrap: 68   Dream    :124   1st Qu.:39.23   1st Qu.:15.60  \n Gentoo   :124   Torgersen: 52   Median :44.45   Median :17.30  \n                                 Mean   :43.92   Mean   :17.15  \n                                 3rd Qu.:48.50   3rd Qu.:18.70  \n                                 Max.   :59.60   Max.   :21.50  \n                                 NA's   :2       NA's   :2      \n flipper_length_mm  body_mass_g       sex        year    \n Min.   :172.0     Min.   :2700   female:165   2007:110  \n 1st Qu.:190.0     1st Qu.:3550   male  :168   2008:114  \n Median :197.0     Median :4050   NA's  : 11   2009:120  \n Mean   :200.9     Mean   :4202                          \n 3rd Qu.:213.0     3rd Qu.:4750                          \n Max.   :231.0     Max.   :6300                          \n NA's   :2         NA's   :2                             \n\n\nAu final, la fonction summary() est très utile dans certaines situations, notamment pour avoir rapidement accès à des statistiques descriptives simples sur toutes les colonnes d’un tableau. Elle reste cependant limitée car d’une part, elle ne fournit pas les variances ou les écarts-types pour les variables numériques, et il est impossible d’avoir des résumés plus fins, pour chaque modalité d’un facteur par exemple. Ici, il serait en effet intéressant d’avoir des informations synthétiques concernant les mesures biométriques des manchots, espèce par espèce, plutôt que toutes espèces confondues. C’est là que la fonction skim() intervient.\n\n\n\n1.5.2 La fonction skim()\nLa fonction skim() fait partie du package skimr. Avant de pouvoir l’utiliser, pensez donc à l’installer et à le charger en mémoire si ce n’est pas déjà fait. Comme pour la fonction summary(), on peut utiliser la fonction skim() sur plusieurs types d’objets. Nous nous contenterons d’examiner ici le cas le plus fréquent : celui des tableaux, groupés avec group_by() ou non.\n\n1.5.2.1 Tableau non groupé\nCommençons par examiner le résultat avec le tableau penguins non groupé :\n\nskim(penguins)\n\n\nData summary\n\n\nName\npenguins\n\n\nNumber of rows\n344\n\n\nNumber of columns\n8\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\nfactor\n3\n\n\nnumeric\n5\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: factor\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nordered\nn_unique\ntop_counts\n\n\n\n\nspecies\n0\n1.00\nFALSE\n3\nAde: 152, Gen: 124, Chi: 68\n\n\nisland\n0\n1.00\nFALSE\n3\nBis: 168, Dre: 124, Tor: 52\n\n\nsex\n11\n0.97\nFALSE\n2\nmal: 168, fem: 165\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nbill_length_mm\n2\n0.99\n43.92\n5.46\n32.1\n39.23\n44.45\n48.5\n59.6\n▃▇▇▆▁\n\n\nbill_depth_mm\n2\n0.99\n17.15\n1.97\n13.1\n15.60\n17.30\n18.7\n21.5\n▅▅▇▇▂\n\n\nflipper_length_mm\n2\n0.99\n200.92\n14.06\n172.0\n190.00\n197.00\n213.0\n231.0\n▂▇▃▅▂\n\n\nbody_mass_g\n2\n0.99\n4201.75\n801.95\n2700.0\n3550.00\n4050.00\n4750.0\n6300.0\n▃▇▆▃▂\n\n\nyear\n0\n1.00\n2008.03\n0.82\n2007.0\n2007.00\n2008.00\n2009.0\n2009.0\n▇▁▇▁▇\n\n\n\n\n\nLes résultats obtenus grâce à cette fonction sont nombreux. La première section nous donne des informations sur le tableau :\n\nson nom, son nombre de lignes et de colonnes\nla nature des variables qu’il contient (ici 3 facteurs et 5 variables numériques)\nla présence de variables utilisées pour faire des regroupements (il n’y en a pas encore à ce stade)\n\nEnsuite, un bloc apporte des informations sur chaque facteur présent dans le tableau :\n\nle nom de la variable catégorielle (skim_variable)\nle nombre de données manquantes (n_missing) et le taux de “données complètes” (complete_rate)\ndes informations sur le nombre de modalités (n_unique)\nle nombre d’observations pour les modalités les plus représentées (top_counts)\n\nEn un coup d’œil, on sait donc que 3 espèces sont présentes (et on connait leurs effectifs), on sait que les manchots ont été échantillonnées sur 3 îles, et on sait que le sexe de 11 individu (sur 344) est inconnu. Pour le reste, il y a presque autant de femelles que de mâles.\nLe dernier bloc renseigne sur les variables numériques. Pour chaque d’elle, on a :\n\nle nom de la variable numérique (skim_variable)\nle nombre de données manquantes (n_missing) et le taux de “données complètes” (complete_rate)\nla moyenne (mean) et l’écart-type (sd), ce qui est une nouveauté par rapport à la fonction summary()\nles valeurs minimales (p0), de premier quartile (p25), de second quartile (p50, c’est la médiane !), de troisième quartile (p75) et la valeur maximale (p100)\nun histogramme très simple qui donne un premier aperçu grossier de la forme de la distribution\n\nLà encore, en un coup d’œil, on dispose donc de toutes les informations pertinentes pour juger de la distribution, de la position et de la dispersion de chaque variable numérique du jeu de données.\n\n\n1.5.2.2 Tableau groupé\nLa fonction skim(), déjà très pratique, le devient encore plus lorsque l’on choisit de lui fournir seulement certaines variables, et qu’on fait certains regroupements. Par exemple, on peut sélectionner les variables relatives aux dimensions du bec (bill_length_mm et bill_depth_mm) avec la fonction select() que nous connaissons déjà, et demander un résumé des données pour chaque espèce grâce à la fonction group_by() que nous connaissons également :\n\npenguins |&gt;                     # Avec le tableau penguins...\n  select(species, \n         bill_length_mm,\n         bill_depth_mm) |&gt;      # Je sélectionne les variables d'intérêt...\n  group_by(species) |&gt;          # Je regroupe par espèce...\n  skim()                         # Et je produis un résumé des données\n\n\nData summary\n\n\nName\ngroup_by(…)\n\n\nNumber of rows\n344\n\n\nNumber of columns\n3\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\nnumeric\n2\n\n\n________________________\n\n\n\nGroup variables\nspecies\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nspecies\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nbill_length_mm\nAdelie\n1\n0.99\n38.79\n2.66\n32.1\n36.75\n38.80\n40.75\n46.0\n▁▆▇▆▁\n\n\nbill_length_mm\nChinstrap\n0\n1.00\n48.83\n3.34\n40.9\n46.35\n49.55\n51.08\n58.0\n▂▇▇▅▁\n\n\nbill_length_mm\nGentoo\n1\n0.99\n47.50\n3.08\n40.9\n45.30\n47.30\n49.55\n59.6\n▃▇▆▁▁\n\n\nbill_depth_mm\nAdelie\n1\n0.99\n18.35\n1.22\n15.5\n17.50\n18.40\n19.00\n21.5\n▂▆▇▃▁\n\n\nbill_depth_mm\nChinstrap\n0\n1.00\n18.42\n1.14\n16.4\n17.50\n18.45\n19.40\n20.8\n▅▇▇▆▂\n\n\nbill_depth_mm\nGentoo\n1\n0.99\n14.98\n0.98\n13.1\n14.20\n15.00\n15.70\n17.3\n▅▇▇▆▂\n\n\n\n\n\nOn constate ici que pour chaque variable numérique sélectionnée, des statistiques descriptives détaillées nous sont fournies pour chacune des 3 espèces. Ce premier examen semble montrer que :\n\nL’espèce Adélie est celle qui possède le bec le plus court (ses valeurs de moyennes, médianes et quartiles sont plus faibles que celles des 2 autres espèces).\nL’espèce Gentoo est celle qui possède le bec le plus fin, ou le moins épais (ses valeurs de moyennes, médianes et quartiles sont plus faibles que celles des 2 autres espèces)\nIl ne semble pas y avoir de fortes différences d’écarts-types (donc des dispersions des points autour des moyennes) entre les 3 espèces : pour chacune des 2 variables numériques, des valeurs d’écarts-types comparables sont en effet observées pour les 3 espèces\nLa distribution des 2 variables numériques semble approximativement suivre une distribution symétrique pour les 3 espèces, avec une forme de courbe en cloche. Les distributions devraient donc suivre à peu une distribution normale\n\n\n\n\n\n\n\nNote\n\n\n\nVous comprenez j’espère l’importance d’examiner ce genre de résumé des données avant de vous lancer dans des tests statistiques. Ils sont un complément indispensable aux explorations graphiques que vous devez également prendre l’habitude de réaliser pour mieux appréhender et comprendre la nature de vos données. Puisque chaque jeu de données est unique, vous devrez vous adapter à la situation et aux questions scientifiques qui vous sont posées (ou que vous vous posez !) : les choix qui seront pertinents pour une situation ne le seront pas nécessairement pour une autre. Mais dans tous les cas, pour savoir où vous allez et pour ne pas faire de bêtise au moment des tests statistiques et de leur interprétation, vous devrez toujours explorer vos données, avec des graphiques exploratoires et des statistiques descriptives(.\n\n\n\n\n\n1.5.3 Exercice\nEn utilisant les fonctions de résumé abordées jusqu’ici et le tableau weather, répondez aux questions suivante :\n\nDans quel aéroport de New York les précipitations moyennes ont-elle été les plus fortes en 2013 ?\nDans quel aéroport de New York la vitesse du vent moyenne était-elle la plus forte en 2013 ? Quelle est cette vitesse ?\nDans quel aéroport de New York les rafales de vent étaient-elles les plus variables en 2013 ? Quel indice statistique vous donne cette information et quelle est sa valeur ?\nLes précipitation dans les 3 aéroports de New-York ont-elles une distribution symétrique ?\nQuelle est la température médiane observée en 2013 tous aéroports confondus ?\nTous aéroports confondus, quel est le mois de l’année où la température a été la plus variable en 2013 ? Quelles étaient les températures minimales et maximales observées ce mois-là ?\n\n\n\n\n\nHorst, Allison, Alison Hill, et Kristen Gorman. 2022. palmerpenguins: Palmer Archipelago (Antarctica) Penguin Data. https://CRAN.R-project.org/package=palmerpenguins.\n\n\nWaring, Elin, Michael Quinn, Amelia McNamara, Eduardo Arino de la Rubia, Hao Zhu, et Shannon Ellis. 2022. skimr: Compact and Flexible Summaries of Data. https://CRAN.R-project.org/package=skimr.\n\n\nWickham, Hadley. 2021. nycflights13: Flights that Departed NYC in 2013. https://github.com/hadley/nycflights13.\n\n\n———. 2022. tidyverse: Easily Install and Load the Tidyverse. https://CRAN.R-project.org/package=tidyverse.\n\n\nWickham, Hadley, Winston Chang, Lionel Henry, Thomas Lin Pedersen, Kohske Takahashi, Claus Wilke, Kara Woo, Hiroaki Yutani, et Dewey Dunnington. 2022. ggplot2: Create Elegant Data Visualisations Using the Grammar of Graphics. https://CRAN.R-project.org/package=ggplot2.\n\n\nWickham, Hadley, Romain François, Lionel Henry, Kirill Müller, et Davis Vaughan. 2023. dplyr: A Grammar of Data Manipulation. https://CRAN.R-project.org/package=dplyr.\n\n\nWickham, Hadley, Jim Hester, et Jennifer Bryan. 2022. readr: Read Rectangular Text Data. https://CRAN.R-project.org/package=readr."
  }
]