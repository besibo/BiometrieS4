[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "TP de Biométrie Semestre 4",
    "section": "",
    "text": "Introduction"
  },
  {
    "objectID": "index.html#objectifs",
    "href": "index.html#objectifs",
    "title": "TP de Biométrie Semestre 4",
    "section": "Objectifs",
    "text": "Objectifs\nCe livre contient l’ensemble du matériel (contenus, exemples, exercices…) nécessaire à la réalisation des travaux pratiques sous R pour la Biométrie de l’EC ‘Outils pour l’étude et la compréhension du vivant 3’ du semestre 4 de la licence Sciences de la Vie de La Rochelle Université.\nÀ l’issue des 3 séances prévues ce semestre (2 TP et 1 TEA), vous devriez être capables de faire les choses suivantes dans le logiciel RStudio :\n\nExplorer des jeux de données en produisant des résumés statistiques de variables de différentes natures (numériques continues ou catégorielles) et en produisant des graphiques appropriés.\nÊtre capables de distinguer les notions de dispersion et d’incertitude.\nCalculer des statistiques descriptives permettant de déterminer la position (moyennes, médianes, quartiles…) et la dispersion des données (écart-types, variances, intervalles inter-quartiles…) pour plusieurs sous-groupes de vos jeux de données, et les représenter sur des graphiques adaptés.\nCalculer des indices d’incertitude (erreurs standard, intervalles de confiance…) pour plusieurs sous-groupes de vos jeux de données, et les représenter sur des graphiques adaptés."
  },
  {
    "objectID": "index.html#sec-prerequis",
    "href": "index.html#sec-prerequis",
    "title": "TP de Biométrie Semestre 4",
    "section": "Pré-requis",
    "text": "Pré-requis\nPour atteindre les objectifs fixés ici, et compte tenu du volume horaire restreint qui est consacré aux TP et TEA de Biométrie au S4, vous devez obligatoirement posséder un certain nombre de pré-requis. En particulier, vous devriez avoir à ce stade une bonne connaissance de l’interface des logiciels R et RStudio, et vous devriez être capables :\n\nde créer un Rproject et un script d’analyse dans RStudio\nd’importer des jeux de données issus de tableurs dans RStudio\nd’effectuer des manipulations de données simples (sélectionner des variables, trier des colonnes, filtrer des lignes, créer de nouvelles variables, etc.)\nde produire des graphiques de qualité, adaptés à la fois aux variables dont vous disposez et aux questions auxquelles vous souhaitez répondre.\n\n\n\n\n\n\n\nSi ces pré-requis ne sont pas maîtrisés\n\n\n\nMettez-vous à niveau de toute urgence en lisant attentivement le livre en ligne de Biométrie du semestre 3"
  },
  {
    "objectID": "index.html#organisation",
    "href": "index.html#organisation",
    "title": "TP de Biométrie Semestre 4",
    "section": "Organisation",
    "text": "Organisation\n\nVolume de travail\nLes travaux pratiques et TEA de biométrie auront lieu entre le 14 mars et le 13 avril 2023 :\n\nEntre le mardi 14 et le mardi 28 mars : 1 séance de TP d’1h30 et 1 séance de TEA d’1h30\nEntre le mardi 11 et le jeudi 13 avril : 1 séance de TP d’1h30\n\n\nTous les TP ont lieu en salle MSI 217. Tous les TEA sont à distance.\nAu total, chaque groupe aura donc 2 séances de TP et 1 séance de TEA, soit un total de 4,5 heures prévues dans vos emplois du temps. C’est peu pour atteindre les objectifs fixés et il y aura donc évidemment du travail personnel à fournir en dehors de ces séances. J’estime que vous devrez fournir 3 à 6 heures de travail personnel en plus des séances prévues dans votre emploi du temps. Attention donc : pensez bien à prévoir du temps dans vos plannings car le travail personnel est essentiel pour progresser dans cette matière. J’insiste sur l’importance de faire l’effort dès maintenant : vous allez en effet avoir des enseignements qui reposent sur l’utilisation de ces logiciels jusqu’à la fin du S6 (y compris pendant vos stages et, très vraisemblablement, dans vos futurs masters également). C’est donc maintenant qu’il faut acquérir des automatismes, cela vous fera gagner énormément de temps ensuite.\n\n\nModalités d’enseignement\nPour suivre cet enseignement vous pourrez utiliser les ordinateurs de l’université, mais je ne peux que vous encourager à utiliser vos propres ordinateurs, sous Windows, Linux ou MacOS. Lors de vos futurs stages et pour rédiger vos comptes-rendus de TP, vous utiliserez le plus souvent vos propres ordinateurs, autant prendre dès maintenant de bonnes habitudes en installant les logiciels dont vous aurez besoin tout au long de votre licence. Si vous n’avez pas suivi la biométrie du semestre 3 et que les logiciels R et RStudio ne sont pas encore installés sur vos ordinateurs, suivez la procédure décrite ici. Si vous ne possédez pas d’ordinateur, manifestez vous rapidement auprès de moi car des solutions existent (prêt par l’université, travail sur tablette via RStudio cloud…).\n\n\n\n\n\n\nImportant\n\n\n\nL’essentiel du contenu de cet enseignement peut être abordé en autonomie, à distance, grâce à ce livre en ligne, aux ressources mises à disposition sur Moodle et à votre ordinateur personnel. Cela signifie que la présence physique lors des séances de TP n’est pas obligatoire.\n\n\nPlus que des séances de TP classiques, considérez plutôt qu’il s’agit de permanences non-obligatoires : si vous pensez avoir besoin d’aide, si vous avez des points de blocage ou des questions sur le contenu de ce document ou sur les exercices demandés, alors venez poser vos questions lors des séances de TP. Vous ne serez d’ailleurs pas tenus de rester pendant 1h30 : si vous obtenez une réponse en 10 minutes et que vous préférez travailler ailleurs, vous serez libres de repartir !\nDe même, si vous n’avez pas de difficulté de compréhension, que vous n’avez pas de problème avec les exercices de ce livre en ligne, votre présence n’est pas requise : tant que le travail demandé est fait, libre à vous de choisir votre façon de travailler. Bien entendu, si vous souhaitez venir en salle de TP pour travailler au calme et dans un cadre plus formel, même si vous n’avez pas de questions à poser : aucun problème, vous y serez toujours les bienvenus et je serai présent systématiquement, pour toutes les séances et tous les groupes.\nCe fonctionnement très souple a de nombreux avantages :\n\nvous vous organisez comme vous le souhaitez\nvous ne venez que lorsque vous en avez vraiment besoin\ncelles et ceux qui se déplacent reçoivent une aide personnalisée\nvous travaillez sur vos ordinateurs\nles effectifs étant réduits, c’est aussi plus confortable pour moi !\n\nToutefois, pour que cette organisation fonctionne, cela demande de la rigueur de votre part, en particulier sur la régularité du travail que vous devez fournir. Si la présence en salle de TP n’est pas requise, le travail demandé est bel et bien obligatoire ! Si vous venez en salle de TP sans avoir travaillé en amont, vous risquez de perdre votre temps car vous passerez votre séance à lire et suivre ce livre en ligne, choses que vous pouvez très bien faire chez vous. De même, si vous attendez le 13 avril pour vous y mettre, je ne pourrais pas grand chose pour vous. Je le répète, outre les heures de TP/TEA prévus dans vos emplois du temps, vous devez prévoir au moins 3 à 6 heures de travail personnel supplémentaire.\nJe vous laisse donc une grande liberté d’organisation. À vous d’en tirer le maximum et de faire preuve du sérieux nécessaire."
  },
  {
    "objectID": "index.html#progression-conseillée",
    "href": "index.html#progression-conseillée",
    "title": "TP de Biométrie Semestre 4",
    "section": "Progression conseillée",
    "text": "Progression conseillée\nSi vous avez suivi le document de prise en main de R et RStudio du semestre 3, vous savez que pour apprendre à utiliser ces logiciels, il faut faire les choses soi-même, ne pas avoir peur des messages d’erreurs (il faut d’ailleurs apprendre à les déchiffrer pour comprendre d’où viennent les problèmes), essayer maintes fois, se tromper beaucoup, recommencer, et surtout, ne pas se décourager. J’utilise ce logiciel presque quotidiennement depuis plus de 15 ans et à chaque session de travail, je rencontre des messages d’erreur. Avec suffisamment d’habitude, on apprend à les déchiffrer, et on corrige les problèmes en quelques secondes. Ce livre est conçu pour vous faciliter la tâche, mais ne vous y trompez pas, vous rencontrerez des difficultés, et c’est normal. C’est le prix à payer pour profiter de la puissance du meilleur logiciel permettant d’analyser des données, de produire des graphiques de qualité et de réaliser toutes les statistiques dont vous aurez besoin d’ici la fin de vos études et au-delà.\nPour que cet apprentissage soit le moins problématique possible, il convient de prendre les choses dans l’ordre. C’est la raison pour laquelle les 3 chapitres de ce livre doivent être lus dans l’ordre, et les exercices d’application faits au fur et à mesure de la lecture.\nIdéalement, voilà les étapes que vous devriez avoir franchi chaque semaine :\n\nÀ l’issue de la première séance de TP et de la première séance de TEA, vous devriez avoir compris comment calculer et interpréter des résumés statistiques de vos jeux de données (c’est le premier chapitre de ce livre en ligne). Vous devriez en particulier être capable de calculer des estimateurs de position (moyennes, médianes, quartiles…) et de dispersion (variances, écart-types, intervalles inter-quartiles…) sur des variables numériques, et ce, pour plusieurs modalités d’une variable catégorielle ou pour chaque combinaison de modalités de plusieurs variables catégorielles (par exemple, quelles sont les moyennes et variances des longueurs de becs pour chaque espèce de manchots et chaque sexe). Vous devrez donc être capables d’utiliser les fonctions group_by() et summarise() du package dplyr. Cela suppose bien sûr que vous soyez au clair sur les pré-requis évoqués plus haut (Section 1) avant d’aborder le premier chapitre de ce livre en ligne.\nÀ l’issue de la seconde séance de TP, Vous devrez être capables de distinguer la notion de dispersion de celle de précision. Vous devrez être capable d’expliquer clairement la différence entre ces 2 notions, et vous devrez savoir à quoi servent les indices de dispersion et d’incertitude. Vous devrez être capables de calculer des indices d’incertitude, en particulier l’erreur standard de la moyenne (ou erreur type) et l’intervalle de confiance de la moyenne (chapitre 2). Vous devrez en outre être capables de produire des graphiques sur lesquels apparaissent des barres d’incertitude (erreurs standards ou intervalles de confiance, chapitre 3). Là encore, cela suppose que vous soyez au clair avec les représentations graphiques abordées au semestre 3 (comment produire un graphique avec ggplot2, quel graphique choisir pour quelles données et quel objectif ?…)"
  },
  {
    "objectID": "index.html#évaluations",
    "href": "index.html#évaluations",
    "title": "TP de Biométrie Semestre 4",
    "section": "Évaluation(s)",
    "text": "Évaluation(s)\nL’évaluation de la partie “Biométrie” de l’EC “Outils pour l’étude et la compréhension du vivant 3” sera conduite par mes collègues en charge des cours magistraux, travaux dirigés, et travaux pratiques “classiques” (Benoît Lebreton et Gérard Blanchard). Il est bien évident toutefois que mes collègues attendent une bonne maîtrise des notions développées ici, et qu’au-delà de la biométrie, les autres collègues intervenant dans l’EC “outils pour l’étude et la compréhension du vivant 3” attendent eux aussi que vous mettiez en pratique ce que vous apprenez ici dans vos futurs compte-rendus de TP."
  },
  {
    "objectID": "index.html#licence",
    "href": "index.html#licence",
    "title": "TP de Biométrie Semestre 4",
    "section": "Licence",
    "text": "Licence\nCe livre est ligne est sous licence Creative Commons (CC BY-NC-ND 4.0)\n\n\n\n\n\nVous êtes autorisé à partager, copier, distribuer et communiquer ce matériel par tous moyens et sous tous formats, tant que les conditions suivantes sont respectées :\n\n\n Attribution : vous devez créditer ce travail (donc citer son auteur), fournir un lien vers ce livre en ligne, intégrer un lien vers la licence Creative Commons et indiquer si des modifications du contenu original ont été effectuées. Vous devez indiquer ces informations par tous les moyens raisonnables, sans toutefois suggérer que l’auteur vous soutient ou soutient la façon dont vous avez utilisé son travail.\n\n\n Pas d’Utilisation Commerciale : vous n’êtes pas autorisé à faire un usage commercial de cet ouvrage, ni de tout ou partie du matériel le composant. Cela comprend évidemment la diffusion sur des plateformes de partage telles que studocu.com qui tirent profit d’œuvres dont elles ne sont pas propriétaires, souvent à l’insu des auteurs.\n\n\n Pas de modifications : dans le cas où vous effectuez un remix, que vous transformez, ou créez à partir du matériel composant l’ouvrage original, vous n’êtes pas autorisé à distribuer ou mettre à disposition l’ouvrage modifié.\n\n\n Pas de restrictions complémentaires : vous n’êtes pas autorisé à appliquer des conditions légales ou des mesures techniques qui restreindraient légalement autrui à utiliser cet ouvrage dans les conditions décrites par la licence."
  },
  {
    "objectID": "03-graphiques.html#pré-requis",
    "href": "03-graphiques.html#pré-requis",
    "title": "3  Visualiser l’incertitude et la dispersion",
    "section": "3.1 Pré-requis",
    "text": "3.1 Pré-requis\nNous avons ici besoin des packages suivants :\n\nlibrary(tidyverse)\nlibrary(palmerpenguins)\nlibrary(nycflights13)\n\nPensez à les charger en mémoire si ce n’est pas déjà fait ou si vous venez de démarrer une nouvelle session de travail.\nIl existe plusieurs façons de représenter visuellement les positions, les dispersions et les incertitudes. Concernant les positions et les dispersions tout d’abord, nous avons déjà vu plusieurs façons de faire au semestre 3, en particulier dans les parties consacrées aux histogrammes, aux stripcharts et aux boxplots. Nous reprenons ici brièvement chacun de ces 3 types de graphique afin de les remettre en contexte avec ce que nous avons appris ici.\nDans un dernier temps, nous verrons comment visualiser l’incertitude associée à des calculs de moyennes ou de variances grâce aux barres d’erreurs ou aux encoches des boîtes à moustaches."
  },
  {
    "objectID": "03-graphiques.html#position-et-dispersion-les-histogrammes",
    "href": "03-graphiques.html#position-et-dispersion-les-histogrammes",
    "title": "3  Visualiser l’incertitude et la dispersion",
    "section": "3.2 Position et dispersion : les histogrammes",
    "text": "3.2 Position et dispersion : les histogrammes\nJe vous renvoie à la partie sur les histogrammes du livre en ligne de biométrie du semestre 3 si vous avez besoin de vous rafraîchir la mémoire. Jetez aussi un œil la partie sur les histogrammes facettés.\nLes histogrammes permettent de déterminer à la fois où se trouvent les valeurs les plus fréquemment observées (la position du pic principal correspond à la tendance centrale), et la dispersion (ou variabilité) des valeurs autour de la tendance centrale. Par exemple, la fonction facet_grid() permet de faire des histogrammes des températures pour chaque aéroport de New York et chaque mois de l’année 2013 :\n\nweather |&gt; \n  mutate(temp_celsius = (temp - 32) / 1.8) |&gt; \n  ggplot(aes(x = temp_celsius, fill = factor(month))) +\n  geom_histogram(bins = 20, color = \"grey20\", show.legend = FALSE) +\n  facet_grid(factor(month) ~ origin, scales = \"free_y\") +\n  labs(x = \"Températures (ºC)\", y = \"Fréquence\") +\n  theme_bw()\n\nWarning: Removed 1 rows containing non-finite values (`stat_bin()`).\n\n\n\n\n\nIci, 36 histogrammes sont produits. Ils permettent de constater que :\n\nles températures évoluent à peu près de la même façon dans les 3 aéroports (les 3 colonnes de graphiques se ressemblent beaucoup).\nles températures moyennes sont plus faibles en hiver qu’en été, et qu’elles sont intermédiaires au printemps et à l’automne. C’est bien la position des pics sur l’axe des abscisses qui nous renseigne là-dessus. On sait aussi que les températures moyennes les plus fortes sont autour de 25ºC en juillet, alors que ces mêmes températures moyennes sont proches de 0ºC en janvier, février et décembre.\nla variabilité des températures est comparable pour la plupart des mois de l’année, avec une exception au mois d’août où la dispersion des valeurs semble plus limitée. Cette fois, c’est l’étalement de l’histogramme qui nous renseigne sur la dispersion."
  },
  {
    "objectID": "03-graphiques.html#position-et-dispersion-les-stripcharts",
    "href": "03-graphiques.html#position-et-dispersion-les-stripcharts",
    "title": "3  Visualiser l’incertitude et la dispersion",
    "section": "3.3 Position et dispersion : les stripcharts",
    "text": "3.3 Position et dispersion : les stripcharts\nUne autre façon de visualiser à la fois les tendances centrales et les dispersions consiste à produire un nuage de points “stripchart”. Là encore, je vous renvoie à la partie sur les stripcharts du livre en ligne de biométrie du semestre 3 si vous avez besoin de vous rafraîchir la mémoire.\n\nweather |&gt; \n  mutate(temp_celsius = (temp - 32) / 1.8) |&gt; \n  ggplot(aes(x = factor(month), y = temp_celsius, fill = factor(month))) +\n  geom_jitter(shape = 21, color = \"grey20\", show.legend = FALSE,\n              width = 0.15, height = 0,\n              alpha = 0.5) +\n  facet_wrap(~ origin, ncol = 1) +\n  labs(x = \"Mois\", y = \"Températures (ºC)\") +\n  theme_bw()\n\nWarning: Removed 1 rows containing missing values (`geom_point()`).\n\n\n\n\n\nCette fois, nous visualisons la totalité des données disponibles, et non les données regroupées dans des classes plus ou moins arbitraires. Mais là encore, on peut facilement comparer la position de chaque série de données : pour les mois d’été, les températures sont plus élevées que pour les mois d’hiver. Et la dispersion des données est aussi facile à comparer entre les mois. Par exemple, la variabilité des températures en janvier est nettement supérieure à celle du mois de février. C’est ici l’étendue du nuage de points sur l’axe des ordonnées qui nous permet de le dire."
  },
  {
    "objectID": "03-graphiques.html#position-et-dispersion-les-boxplots",
    "href": "03-graphiques.html#position-et-dispersion-les-boxplots",
    "title": "3  Visualiser l’incertitude et la dispersion",
    "section": "3.4 Position et dispersion : les boxplots",
    "text": "3.4 Position et dispersion : les boxplots\nLa dernière façon classique de visualiser à la fois les tendances centrales et les dispersions consiste à produire un graphique boîtes à moustaches, ou “boxplot”. Là encore, je vous renvoie à la partie sur les boxplots du livre en ligne de biométrie du semestre 3 si vous avez besoin de vous rafraîchir la mémoire.\n\nweather |&gt; \n  mutate(temp_celsius = (temp - 32) / 1.8) |&gt; \n  ggplot(aes(x = factor(month), y = temp_celsius, fill = factor(month))) +\n  geom_boxplot(show.legend = FALSE, alpha = 0.5) +\n  facet_wrap(~ origin, ncol = 1) +\n  labs(x = \"Mois\", y = \"Températures (ºC)\") +\n  theme_bw()\n\nWarning: Removed 1 rows containing non-finite values (`stat_boxplot()`).\n\n\n\n\n\nVous voyez que le code est très proche pour produire un stripchart ou un boxplot. Comme indiqué au semestre 3, les différents éléments de chaque boîte nous renseignent sur la position et sur la dispersion des données pour chaque mois et chaque aéroport :\n\nLa limite inférieure de la boîte correspond au premier quartile : 25% des données de l’échantillon sont situées au-dessous de cette valeur.\nLa limite supérieure de la boîte correspond au troisième quartile : 75% des données de l’échantillon sont situées au-dessous de cette valeur.\nLe segment épais à l’intérieur de la boîte correspond au second quartile : c’est la médiane de l’échantillon, qui nous renseigne sur la position de la distribution. 50% des données de l’échantillon sont situées au-dessus de cette valeur, et 50% au-dessous.\nLa hauteur de la boîte correspond à l’étendue (ou intervalle) interquartile ou Inter Quartile Range (IQR) en anglais. On trouve dans cette boîte 50% des observations de l’échantillon. C’est une mesure de la dispersion des 50% des données les plus centrales. Une boîte plus allongée indique donc une plus grande dispersion.\nLes moustaches correspondent à des valeurs qui sont en dessous du premier quartile (pour la moustache du bas) et au-dessus du troisième quartile (pour la moustache du haut). La règle utilisée dans R est que ces moustaches s’étendent jusqu’aux valeurs minimales et maximales de l’échantillon, mais elles ne peuvent en aucun cas s’étendre au-delà de 1,5 fois la hauteur de la boîte (1,5 fois l’IQR) vers le haut et le bas. Si des points apparaissent au-delà des moustaches (vers le haut ou le bas), ces points sont appelés “outliers”. On peut en observer ici pour plusieurs mois et pour les 3 aéroports (par exemple, en avril dans les 3 aéroports). Ce sont des points qui s’éloignent du centre de la distribution de façon importante puisqu’ils sont au-delà de 1,5 fois l’IQR de part et d’autre du premier ou du troisième quartile. Il peut s’agir d’anomalies de mesures, d’anomalies de saisie des données, ou tout simplement, d’enregistrements tout à fait valides mais atypiques ou extrêmes ; ll ne s’agit donc pas toujours de point aberrants. J’attire votre attention sur le fait que la définition de ces outliers est relativement arbitraire. Nous pourrions faire le choix d’étendre les moustaches jusqu’à 1,8 fois l’IQR (ou 2, ou 2,5). Nous observerions alors beaucoup moins d’outliers. D’une façons générale, la longueur des moustaches renseigne sur la variabilité des données en dehors de la zone centrale. Plus elles sont longues, plus la variabilité est importante. Très souvent, l’examen attentif des outliers est utile car il nous permet d’en apprendre plus sur le comportement extrême de certaines observations.\n\nLorsque les boîtes ont une forme à peu près symétrique de part et d’autre de la médiane (c’est le cas pour cet exemple dans la plupart des catégories), cela signifie qu’un histogramme des mêmes données serait symétrique également.\nLes stripcharts et les boxplots sont donc un bon moyen de comparer rapidement la position et la dispersion d’un grand nombre de séries de données : ici, en quelques lignes de code, nous en comparons 12 pour chacun des 3 aéroports de New York.\nLes histogrammes sont plus utiles lorsqu’il y a moins de catégories à comparer. Ils permettent en outre de mieux visualiser les distributions non symétriques, ou qui présentent plusieurs pics (distribution bi- ou poly-modales)."
  },
  {
    "objectID": "03-graphiques.html#visualiser-lincertitude-les-barres-derreur",
    "href": "03-graphiques.html#visualiser-lincertitude-les-barres-derreur",
    "title": "3  Visualiser l’incertitude et la dispersion",
    "section": "3.5 Visualiser l’incertitude : les barres d’erreur",
    "text": "3.5 Visualiser l’incertitude : les barres d’erreur\nComme évoqué plus haut, il est important de ne pas confondre dispersion et incertitude. Lorsque l’on visualise des moyennes calculées à partir des données d’un échantillon, il est important de faire apparaître des barres d’erreurs, qui correspondent en général :\n\nsoit à l’erreur standard de la moyenne\nsoit à l’intervalle de confiance à 95% de la moyenne\n\nPuisque deux choix sont possibles, il sera important de préciser systématiquement dans la légende du graphique, la nature des barres représentées. Commençons par visualiser les températures mensuelles avec les erreurs standards. Pour cela, je reprends le tableau temperatures_se créé précédemment :\n\ntemperatures_se |&gt; \n  ggplot(aes(x = factor(month), y = moyenne)) +\n  geom_line(aes(group = 1)) +\n  geom_point() +\n  geom_errorbar(aes(ymin = moyenne - erreur_standard,\n                    ymax = moyenne + erreur_standard),\n                width = 0.1) +\n  facet_wrap(~origin, ncol = 1) +\n  labs(x = \"Mois\", \n       y = \"Moyenne des températures quotidiennes maximales (ºC)\") +\n  theme_bw()\n\n\n\n\nFigure 3.1: Températures moyennes mensuelles observées en 2013 dans les 3 aéroports de New York. Les barres d’erreur sont les erreurs standard\n\n\n\n\nVous remarquerez que :\n\nj’associe factor(month), et non simplement month, à l’axe des x afin d’avoir, sur l’axe des abscisses, des chiffres cohérents allant de 1 à 12, et non des chiffres à virgule.\nl’argument group = 1 doit être ajouté pour que la ligne reliant les points apparaisse. En effet, les lignes sont censées relier des points qui appartiennent à une même série temporelle. Or ici, nous avons transformé month en facteur. Préciser group = 1 permet d’indiquer à geom_line() que toutes les catégories du facteur month appartiennent au même groupe, que ce facteur peut être considéré comme une variable continue, et qu’il est donc correct de relier les points.\nla fonction geom_errorbar() contient de nouvelles caractéristiques esthétiques qu’il nous faut obligatoirement renseigner : les extrémités inférieures et supérieures des barres d’erreur. Il nous faut donc associer 2 variables à ces caractéristiques esthétiques. Ici, nous utilisons moyenne - erreur_std pour la borne inférieure des barres d’erreur, et moyenne + erreur_std pour la borne supérieure. Les variables moyenne et erreur_standard faisant partie du tableau temperatures_se, geom_errorbar() les trouve sans difficulté.\nl’argument width de la fonction geom_errorbar() permet d’indiquer la longueur des segments horizontaux qui apparaissent à chaque extrémité des barres d’erreur.\n\nIci, bien que moins lisible, on peut aussi faire apparaître les trois courbes sur le même graphique, afin de mieux visualiser les similarités des fluctuations de températures entre les 3 aéroports :\n\ntemperatures_se |&gt; \n  ggplot(aes(x = factor(month), y = moyenne, color = origin, group = origin)) +\n  geom_line() +\n  geom_point() +\n  geom_errorbar(aes(ymin = moyenne - erreur_standard,\n                    ymax = moyenne + erreur_standard),\n                width = 0.1) +\n  labs(x = \"Mois\", \n       y = \"Moyenne des températures quotidiennes maximales (ºC)\",\n       color = \"Aéroport\") +\n  theme_bw()\n\n\n\n\nFigure 3.2: Températures moyennes mensuelles observées en 2013 dans les 3 aéroports de New York. Les barres d’erreur sont les erreurs standard.\n\n\n\n\nNous pouvons arriver au même résultats en utilisant le tableau temperature_se_bornes, qui contient des variables différentes :\n\ntemperature_se_bornes |&gt; \n  ggplot(aes(x = factor(month), y = moyenne, color = origin, group = origin)) +\n  geom_line() +\n  geom_point() +\n  geom_errorbar(aes(ymin = moyenne_moins_se,\n                    ymax = moyenne_plus_se),\n                width = 0.1) +\n  labs(x = \"Mois\", \n       y = \"Moyenne des températures quotidiennes maximales (ºC)\",\n       color = \"Aéroport\") +\n  theme_bw()\n\n\n\n\nFigure 3.3: Températures moyennes mensuelles observées en 2013 dans les 3 aéroports de New York. Les barres d’erreur sont les erreurs standard.\n\n\n\n\nDe la même façon, nous pouvons parfaitement faire apparaître, au lieu des erreurs standards, les intervalles de confiance à 95% de chaque valeur de température moyenne. Il nous suffit pour cela d’utiliser le tableau temperatures_ci qui contient les valeurs de moyennes et des bornes supérieures et inférieures de ces intervalles :\n\ntemperature_ci |&gt; \n  ggplot(aes(x = factor(month), y = moyenne, group = 1)) +\n  geom_line() +\n  geom_point() +\n  geom_errorbar(aes(ymin = ci_borne_inf, ymax = ci_borne_sup), width = 0.1) +\n  facet_wrap(~origin, ncol = 1) +\n  labs(x = \"Mois\", \n       y = \"Moyenne des températures quotidiennes maximales (ºC)\",\n       color = \"Aéroport\") +\n  theme_bw()\n\n\n\n\nFigure 3.4: Températures moyennes mensuelles observées en 2013 dans les 3 aéroports de New York. Les barres d’erreur sont les intervalels de confiance à 95% des moyenes mensuelles.\n\n\n\n\nComme vous voyez, les barres d’erreurs sont maintenant plus longues que sur la Figure 3.1. C’est normal car rappelez-vous que les intervalles de confiance sont à peu près équivalents à 2 fois les erreurs standards. L’intérêt de représenter les intervalles de confiance est qu’ils sont directement liés aux tests statistiques que nous aborderons en L3. Globalement, quand 2 séries de données ont des intervalles de confiance qui se chevauchent largement (comme les mois de janvier et février par exemple), alors, un test d’hypothèses conclurait presque toujours à l’absence de différence significative entre les 2 groupes. À l’inverse, quand 2 séries de données ont des intervalles de confiance qui ne se chevauchent pas du tout (comme les mois de mars et d’avril par exemple), alors, un test d’hypothèses conclurait presque toujours à l’existence d’une différence significative entre les 2 groupes. Lorsque les intervalles de confiance entre 2 catégories se chevauchent faiblement ou partiellement (comme entre les mois de juin et juillet pour l’aéroport LGA), la situation est moins tranchée, et nous devrons nous en remettre aux résultats du test pour savoir si la différence observée devrait être considérée comme significative ou non."
  },
  {
    "objectID": "03-graphiques.html#visualiser-lincertitude-les-boîtes-à-moustaches",
    "href": "03-graphiques.html#visualiser-lincertitude-les-boîtes-à-moustaches",
    "title": "3  Visualiser l’incertitude et la dispersion",
    "section": "3.6 Visualiser l’incertitude : les boîtes à moustaches",
    "text": "3.6 Visualiser l’incertitude : les boîtes à moustaches\nOutre les informations de position et de dispersion, les boîtes à moustaches permettent également de visualiser l’incertitude associée aux médianes. Il suffit pour cela d’ajouter l’argument notch = TRUE dans la fonction geom_boxplot() :\n\nweather |&gt; \n  mutate(temp_celsius = (temp - 32) / 1.8) |&gt; \n  ggplot(aes(x = factor(month), y = temp_celsius, fill = factor(month))) +\n  geom_boxplot(show.legend = FALSE, alpha = 0.5, notch = TRUE) +\n  facet_wrap(~ origin, ncol = 1) +\n  labs(x = \"Mois\", y = \"Températures (ºC)\") +\n  theme_bw()\n\nWarning: Removed 1 rows containing non-finite values (`stat_boxplot()`).\n\n\n\n\n\nDes encoches ont été ajoutées autour de la médiane de chaque boîte à moustache. Ces encoches sont des encoches d’incertitudes. Les limites inférieures et supérieures de ces encoches correspondent aux bornes inférieures et supérieures de l’intervalle de confiance à 95% des médianes. Comme pour les moyennes, le chevauchement ou l’absence de chevauchement entre les encoches de 2 séries de données nous renseigne sur l’issue probable des futurs tests statistiques que nous serions amenés à réaliser. Il sera donc important de bien examiner ces encoches en amont des tests statistiques pour éviter de faire/dire des bêtises…"
  },
  {
    "objectID": "03-graphiques.html#sec-ploterrbar",
    "href": "03-graphiques.html#sec-ploterrbar",
    "title": "3  Visualiser l’incertitude et la dispersion",
    "section": "3.7 Exercice",
    "text": "3.7 Exercice\n\nAvec le tableau penguins, calculez les grandeurs suivantes pour chaque espèce de manchot et chaque sexe :\n\n\nla moyenne de la longueur des nageoires\nla variance de la longueur des nageoires\nl’écart-type de la longueur des nageoires\nl’erreur standard de la longueur moyenne des nageoires\nla moyenne de la masse corporelle\nla variance de la masse corporelle\nl’écart-type de la masse corporelle\nl’erreur standard de la masse corporelle moyenne\n\nAttention : pensez à retirer les individus dont le sexe est inconnu.\n\nVérifiez avec la fonction skim() que les moyennes et écart-types calculés ci-dessus sont corrects.\nAvec ces données synthétiques faites le graphique suivant :"
  },
  {
    "objectID": "04-corrections.html#correction-de-lexercice-de-la-sec-exo10",
    "href": "04-corrections.html#correction-de-lexercice-de-la-sec-exo10",
    "title": "4  Correction des exercices",
    "section": "4.1 Correction de l’exercice de la Section 1.2.5",
    "text": "4.1 Correction de l’exercice de la Section 1.2.5\n\nAvec le tableau diamonds du package ggplot2, faites un tableau indiquant combien de diamants de chaque couleur on dispose.\n\n\ndiamonds |&gt; \n  count(color)\n\n# A tibble: 7 × 2\n  color     n\n  &lt;ord&gt; &lt;int&gt;\n1 D      6775\n2 E      9797\n3 F      9542\n4 G     11292\n5 H      8304\n6 I      5422\n7 J      2808\n\n\n\nExaminez le tableau weather du package nycflights13 et lisez son fichier d’aide pour comprendre à quoi correspondent les données et comment elles ont été acquises.\n\n\nweather\n?weahter\n\n\nÀ partir du tableau weather faites un tableau indiquant les vitesses de vents minimales, maximales et moyennes, enregistrées chaque mois dans chaque aéroport de New York. Indice : les 3 aéroports de New York sont Newark, LaGuardia Airport et John F. Kennedy, notés respectivement EWR, LGA et JFK dans la variable origin.\n\n\nwindy &lt;- weather |&gt;\n  summarise(max_wind = max(wind_speed, na.rm = TRUE),\n            min_wind = min(wind_speed, na.rm = TRUE),\n            moy_wind = mean(wind_speed, na.rm = TRUE),\n            .by = c(origin, month))\nwindy\n\n# A tibble: 36 × 5\n   origin month max_wind min_wind moy_wind\n   &lt;chr&gt;  &lt;int&gt;    &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n 1 EWR        1     42.6        0     9.87\n 2 EWR        2   1048.         0    12.2 \n 3 EWR        3     29.9        0    11.6 \n 4 EWR        4     25.3        0     9.63\n 5 EWR        5     33.4        0     8.49\n 6 EWR        6     34.5        0     9.55\n 7 EWR        7     20.7        0     9.15\n 8 EWR        8     21.9        0     7.62\n 9 EWR        9     23.0        0     8.03\n10 EWR       10     26.5        0     8.32\n# ℹ 26 more rows\n\n\n\nSachant que les vitesses du vent sont exprimées en miles par heure, certaines valeurs sont-elles surprenantes ? À l’aide de la fonction filter(), éliminez la ou les valeurs aberrantes.\n\nOui, les vitesses de vent supérieures à 100 mph devraient être rares :\n\nwindy |&gt; \n  filter(max_wind &gt; 100)\n\n# A tibble: 1 × 5\n  origin month max_wind min_wind moy_wind\n  &lt;chr&gt;  &lt;int&gt;    &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n1 EWR        2    1048.        0     12.2\n\n\nIci, 1048 mph est impossible. Il s’agit soit d’un dysfonctionnement de l’appareil de mesure, soit d’une erreur de saisie. Pour éliminer cette valeur aberrante, on utilise filter() :\n\nwindy2 &lt;- weather |&gt;\n  filter(wind_speed &lt;= 500) |&gt;\n  summarise(max_wind = max(wind_speed, na.rm = TRUE),\n            min_wind = min(wind_speed, na.rm = TRUE),\n            moy_wind = mean(wind_speed, na.rm = TRUE),\n            .by = c(origin, month))\nwindy2\n\n# A tibble: 36 × 5\n   origin month max_wind min_wind moy_wind\n   &lt;chr&gt;  &lt;int&gt;    &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n 1 EWR        1     42.6        0     9.87\n 2 EWR        2     31.1        0    10.7 \n 3 EWR        3     29.9        0    11.6 \n 4 EWR        4     25.3        0     9.63\n 5 EWR        5     33.4        0     8.49\n 6 EWR        6     34.5        0     9.55\n 7 EWR        7     20.7        0     9.15\n 8 EWR        8     21.9        0     7.62\n 9 EWR        9     23.0        0     8.03\n10 EWR       10     26.5        0     8.32\n# ℹ 26 more rows\n\n\n\nEn utilisant les données de vitesse de vent du tableau weather, produisez le graphique suivant :\n\n\nweather |&gt;\n  filter(wind_speed &lt; 500) |&gt;\n  ggplot(aes(x = factor(month), y = wind_speed)) +\n  geom_jitter(width = 0.2, height = 0, alpha = 0.2) +\n  labs(x = \"Mois\",\n       y = \"Vitesse du vent (mph)\")\n\n\n\n\n\nÀ votre avis :\n\n\npourquoi les points sont-ils organisés en bandes horizontales ?\n\nParce que l’appareil de mesure enregistre probablement des vitesses de vent arrondies au mile par heure le plus proche (pas de valeurs enregsitrées), ou parce que les valeurs ont été arrondies à l’entier le plus proche avant enregistrement dans la base de données.\n\npourquoi n’y a-t-il jamais de vent entre 0 et environ 3 miles à l’heure (mph) ?\n\nCela est probablement dû au seuil de détection de l’appareil d’enregistrement qui est incapable de détecter des des vitesses inferieures à ce seuil. Cela ne veut pas dire qu’il n’y a jamais eu de vent inférieur à 3 mph.\n\nSachant qu’en divisant des mph par 1.151 on obtient des vitesses en nœuds, que nous apprend cette commande :\n\n\nsort(unique(weather$wind_speed)) / 1.151\n\n [1]   0.000000   2.999427   3.999235   4.999044   5.998853   6.998662\n [7]   7.998471   8.998280   9.998089  10.997897  11.997706  12.997515\n[13]  13.997324  14.997133  15.996942  16.996751  17.996560  18.996368\n[19]  19.996177  20.995986  21.995795  22.995604  23.995413  24.995222\n[25]  25.995030  26.994839  27.994648  28.994457  29.994266  30.994075\n[31]  31.993884  32.993692  33.993501  34.993310  36.992928 910.825873\n\n\nQue l’appareil n’enregistre que des vitesses de vent entières, en nœuds, à partir de 3 nœuds (3, 4, 5, etc.). La transformation en mph n’est probablement effectuées qu’ensuite et explique les erreurs d’arrondis."
  },
  {
    "objectID": "04-corrections.html#correction-de-lexercice-de-la-sec-exo20",
    "href": "04-corrections.html#correction-de-lexercice-de-la-sec-exo20",
    "title": "4  Correction des exercices",
    "section": "4.2 Correction de l’exercice de la Section 1.5.3",
    "text": "4.2 Correction de l’exercice de la Section 1.5.3\nEn utilisant les fonctions de résumé abordées jusqu’ici et le tableau weather, répondez aux questions suivante :\n\nDans quel aéroport de New York les précipitations moyennes ont-elle été les plus fortes en 2013 ?\n\n\nweather |&gt; \n  summarise(precip_moyenne = mean(precip), .by = origin) |&gt; \n  arrange(desc(precip_moyenne))\n\n# A tibble: 3 × 2\n  origin precip_moyenne\n  &lt;chr&gt;           &lt;dbl&gt;\n1 EWR           0.00504\n2 LGA           0.00438\n3 JFK           0.00398\n\n\nLes précipitations horaires moyennes les plus fortes sont enregistrées dans l’aéroport EWR (Newark). Si on s’intéresse plutôt aux précipitations mensuelles :\n\nweather |&gt; \n  group_by(origin, month) |&gt; \n  summarise(precip_tot = sum(precip)) |&gt;       # Cumul de précipitation chaque mois et dans chaqe aéroport\n  summarise(precip_moy = mean(precip_tot)) |&gt;  # Calcul des moyennes mensuelles pour chaque aeroport \n  arrange(desc(precip_moy))                     # Tri par ordre décroissant de précipitations moyennes\n\n`summarise()` has grouped output by 'origin'. You can override using the\n`.groups` argument.\n\n\n# A tibble: 3 × 2\n  origin precip_moy\n  &lt;chr&gt;       &lt;dbl&gt;\n1 EWR          3.66\n2 LGA          3.18\n3 JFK          2.89\n\n\nLogiquement, c’est toujours dans l’aéroport de Newark que les précipitations mensuelles moyennes sont les plus fortes (3,66 pouces par mois en moyenne).\n\nDans quel aéroport de New York la vitesse du vent moyenne était-elle la plus forte en 2013 ? Quelle est cette vitesse ?\n\n\nweather |&gt; \n  summarise(wind_moyenne = mean(wind_speed, na.rm = TRUE),\n            .by = origin) |&gt; \n  arrange(desc(wind_moyenne))\n\n# A tibble: 3 × 2\n  origin wind_moyenne\n  &lt;chr&gt;         &lt;dbl&gt;\n1 JFK           11.5 \n2 LGA           10.6 \n3 EWR            9.46\n\n\nLe vent moyen le plus fort est observé à JFK, et vaut 11.5 miles à l’heure. Attention, ça n’est pas le vent le plus fort observé, mais bien le vent moyen le plus fort.\n\nDans quel aéroport de New York les rafales de vent étaient-elles les plus variables en 2013 ? Quel indice statistique vous donne cette information et quelle est sa valeur ?\n\n\nweather |&gt; \n  summarise(rafales_var = var(wind_gust, na.rm = TRUE),\n            .by = origin) |&gt; \n  arrange(desc(rafales_var))\n\n# A tibble: 3 × 2\n  origin rafales_var\n  &lt;chr&gt;        &lt;dbl&gt;\n1 JFK           37.5\n2 LGA           32.8\n3 EWR           31.2\n\n\nC’est à l’aéroport JFK que les rafales de vent étaient les plus variables en 2013. La variance de 37.5 mph\\(^2\\) nous renseigne sur cette variabilité. Une autre façon d’arriver à cette même conclusion consiste à utiliser la fonction skim() sur la variable wind_gust et les données groupées par aéroport (variable origin) :\n\nweather |&gt; \n  select(origin, wind_gust) |&gt; \n  group_by(origin) |&gt; \n  skim()\n\n\nData summary\n\n\nName\ngroup_by(select(weather, …\n\n\nNumber of rows\n26115\n\n\nNumber of columns\n2\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\nnumeric\n1\n\n\n________________________\n\n\n\nGroup variables\norigin\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\norigin\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nwind_gust\nEWR\n6901\n0.21\n24.14\n5.58\n16.11\n19.56\n23.02\n27.33\n58.69\n▇▅▁▁▁\n\n\nwind_gust\nJFK\n7199\n0.17\n27.56\n6.13\n16.11\n23.02\n26.47\n31.07\n66.75\n▇▇▁▁▁\n\n\nwind_gust\nLGA\n6678\n0.23\n25.14\n5.73\n16.11\n20.71\n24.17\n27.62\n62.14\n▇▅▁▁▁\n\n\n\n\n\nIci, c’est l’indice noté sd qui nous renseigne. Il s’agit de l’écart-type qui est exprimé dans la même unité que les données de départ. La variabilité des rafales de vent est donc bien la plus forte à l’aéroport JFK, avec un écart-type de 6.13 mph.\n\nLes précipitation dans les 3 aéroports de New-York ont-elles une distribution symétrique ?\n\n\nweather |&gt; \n  ggplot(aes(x = precip, fill = origin)) +\n  geom_histogram(alpha = 0.5, show.legend = FALSE) +\n  geom_rug() +\n  facet_wrap(~origin, ncol = 1)\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\nLa distribution des précipitations est très clairement asymétrique, avec un très grand nombre de relevés avec aucune précipitation (ce qui explique la très grande barre à la valeur 0), puis une diminution rapide des fréquences auxquelles les précipitations importantes sont observées. D’ailleurs, même en retirant les enregistrement où aucune précipitation n’est détectée, la distribution n’est pas non plus symétrique :\n\nweather |&gt; \n  filter(precip &gt; 0 ) |&gt; \n  ggplot(aes(x = precip, fill = origin)) +\n  geom_histogram(alpha = 0.5, show.legend = FALSE) +\n  geom_rug() +\n  facet_wrap(~origin, ncol = 1)\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\nQuelle est la température médiane observée en 2013 tous aéroports confondus ?\n\n\nweather |&gt; \n  summarise(temo_med = median(temp, na.rm = TRUE))\n\n# A tibble: 1 × 1\n  temo_med\n     &lt;dbl&gt;\n1     55.4\n\n\nLa température médiane, tous aéroports confondue, observée en 2013, vaut 55.4 degrés Fahrenheit.\n\nTous aéroports confondus, quel est le mois de l’année où la température a été la plus variable en 2013 ? Quelles étaient les températures minimales et maximales observées ce mois-là ?\n\n\nweather |&gt; \n  group_by(month) |&gt; \n  summarise(temp_var = var(temp, na.rm = TRUE),\n            temp_sd  = sd(temp, na.rm = TRUE),\n            temp_min = min(temp, na.rm = TRUE),\n            temp_max = max(temp, na.rm = TRUE)) |&gt; \n  arrange(desc(temp_var))\n\n# A tibble: 12 × 5\n   month temp_var temp_sd temp_min temp_max\n   &lt;int&gt;    &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n 1    11    109.    10.4      21.0     71.1\n 2     1    105.    10.2      10.9     64.4\n 3    12     99.6    9.98     18.0     71.6\n 4     5     93.7    9.68     13.1     93.0\n 5    10     78.3    8.85     33.1     89.1\n 6     4     77.2    8.79     30.9     84.0\n 7     9     71.7    8.47     48.0     95  \n 8     6     56.9    7.55     54.0     93.9\n 9     7     50.7    7.12     64.0    100. \n10     2     48.8    6.98     16.0     55.9\n11     3     39.1    6.25     26.1     60.1\n12     8     27.0    5.19     59       90.0\n\n\nC’est en Novembre que les températures ont été les plus variables avec un écart-type de 10.4 degrés Fahrenheit. Ce même mois, la température minimale observée était de 21ºF et la température maximale de 71.1ºF."
  },
  {
    "objectID": "04-corrections.html#correction-de-lexercice-de-la-sec-ploterrbar",
    "href": "04-corrections.html#correction-de-lexercice-de-la-sec-ploterrbar",
    "title": "4  Correction des exercices",
    "section": "4.3 Correction de l’exercice de la Section 3.7",
    "text": "4.3 Correction de l’exercice de la Section 3.7\n\nAvec le tableau penguins, calculez les grandeurs suivantes pour chaque espèce de manchot et chaque sexe :\n\n\nla moyenne de la longueur des nageoires\nla variance de la longueur des nageoires\nl’écart-type de la longueur des nageoires\nl’erreur standard de la longueur moyenne des nageoires\nla moyenne de la masse corporelle\nla variance de la masse corporelle\nl’écart-type de la masse corporelle\nl’erreur standard de la masse corporelle moyenne\n\nAttention : pensez à retirer les individus dont le sexe est inconnu.\n\nresum &lt;- penguins |&gt; \n  filter(!is.na(sex)) |&gt; \n  summarise(moy_L_nageoire = mean(flipper_length_mm, na.rm = TRUE),\n            var_L_nageoire = var(flipper_length_mm, na.rm = TRUE),\n            sd_L_nageoire = sd(flipper_length_mm, na.rm = TRUE),\n            se_L_nageoire = sd_L_nageoire/sqrt(n()),\n            moy_mass = mean(body_mass_g, na.rm = TRUE),\n            var_mass = var(body_mass_g, na.rm = TRUE),\n            sd_mass = sd(body_mass_g, na.rm = TRUE),\n            se_mass = sd_mass/sqrt(n()),\n            .by = c(species, sex))\n\nresum\n\n\n\n# A tibble: 6 × 10\n  species   sex    moy_L_nageoire var_L_nageoire sd_L_nageoire se_L_nageoire\n  &lt;fct&gt;     &lt;fct&gt;           &lt;dbl&gt;          &lt;dbl&gt;         &lt;dbl&gt;         &lt;dbl&gt;\n1 Adelie    male             192.           43.6          6.60         0.772\n2 Adelie    female           188.           31.3          5.60         0.655\n3 Gentoo    female           213.           15.2          3.90         0.512\n4 Gentoo    male             222.           32.2          5.67         0.726\n5 Chinstrap female           192.           33.1          5.75         0.987\n6 Chinstrap male             200.           35.7          5.98         1.02 \n  moy_mass var_mass sd_mass se_mass\n     &lt;dbl&gt;    &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;\n1    4043.  120278.    347.    40.6\n2    3369.   72566.    269.    31.5\n3    4680.   79286.    282.    37.0\n4    5485.   98068.    313.    40.1\n5    3527.   81415.    285.    48.9\n6    3939.  131144.    362.    62.1\n\n\n\nVérifiez avec la fonction skim() que les moyennes et écart-types calculés ci-dessus sont corrects.\n\n\npenguins |&gt; \n  filter(!is.na(sex)) |&gt; \n  group_by(species, sex) |&gt; \n  select(flipper_length_mm, body_mass_g) |&gt; \n  skim()\n\nAdding missing grouping variables: `species`, `sex`\n\n\n\nData summary\n\n\nName\nselect(…)\n\n\nNumber of rows\n333\n\n\nNumber of columns\n4\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\nnumeric\n2\n\n\n________________________\n\n\n\nGroup variables\nspecies, sex\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nspecies\nsex\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nflipper_length_mm\nAdelie\nfemale\n0\n1\n187.79\n5.60\n172\n185.00\n188.0\n191.00\n202\n▁▂▇▅▁\n\n\nflipper_length_mm\nAdelie\nmale\n0\n1\n192.41\n6.60\n178\n189.00\n193.0\n197.00\n210\n▃▅▇▃▁\n\n\nflipper_length_mm\nChinstrap\nfemale\n0\n1\n191.74\n5.75\n178\n187.25\n192.0\n195.75\n202\n▂▅▇▇▆\n\n\nflipper_length_mm\nChinstrap\nmale\n0\n1\n199.91\n5.98\n187\n196.00\n200.5\n203.00\n212\n▁▇▅▅▂\n\n\nflipper_length_mm\nGentoo\nfemale\n0\n1\n212.71\n3.90\n203\n210.00\n212.0\n215.00\n222\n▁▇▆▅▂\n\n\nflipper_length_mm\nGentoo\nmale\n0\n1\n221.54\n5.67\n208\n218.00\n221.0\n225.00\n231\n▁▆▇▇▆\n\n\nbody_mass_g\nAdelie\nfemale\n0\n1\n3368.84\n269.38\n2850\n3175.00\n3400.0\n3550.00\n3900\n▅▅▇▅▅\n\n\nbody_mass_g\nAdelie\nmale\n0\n1\n4043.49\n346.81\n3325\n3800.00\n4000.0\n4300.00\n4775\n▃▇▇▇▃\n\n\nbody_mass_g\nChinstrap\nfemale\n0\n1\n3527.21\n285.33\n2700\n3362.50\n3550.0\n3693.75\n4150\n▁▂▇▇▂\n\n\nbody_mass_g\nChinstrap\nmale\n0\n1\n3938.97\n362.14\n3250\n3731.25\n3950.0\n4100.00\n4800\n▃▇▇▂▂\n\n\nbody_mass_g\nGentoo\nfemale\n0\n1\n4679.74\n281.58\n3950\n4462.50\n4700.0\n4875.00\n5200\n▂▅▇▇▃\n\n\nbody_mass_g\nGentoo\nmale\n0\n1\n5484.84\n313.16\n4750\n5300.00\n5500.0\n5700.00\n6300\n▂▆▇▅▂\n\n\n\n\n\n\nAvec ces données synthétiques faites le graphique suivant :\n\n\nresum |&gt; \n  ggplot(aes(x = sex, y = moy_L_nageoire)) +\n  geom_point() +\n  geom_errorbar(aes(ymin = moy_L_nageoire - se_L_nageoire,\n                    ymax = moy_L_nageoire + se_L_nageoire),\n                width = 0.15) +\n  facet_wrap(~species) +\n  labs(x = \"Sexe\",\n       y = \"Longueur des nageoires (mm)\",\n       title = \"Moyennes (et erreurs standard) des longueurs de nageoires\\nchez les mâles et les femelles de trois espèces de manchots\") +\n  theme_bw()"
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Horst, Allison, Alison Hill, and Kristen Gorman. 2022.\nPalmerpenguins: Palmer Archipelago (Antarctica) Penguin Data.\nhttps://CRAN.R-project.org/package=palmerpenguins.\n\n\nWaring, Elin, Michael Quinn, Amelia McNamara, Eduardo Arino de la Rubia,\nHao Zhu, and Shannon Ellis. 2022. Skimr: Compact and Flexible\nSummaries of Data. https://CRAN.R-project.org/package=skimr.\n\n\nWickham, Hadley. 2021. Nycflights13: Flights That Departed NYC in\n2013. https://github.com/hadley/nycflights13.\n\n\n———. 2022. Tidyverse: Easily Install and Load the Tidyverse. https://CRAN.R-project.org/package=tidyverse.\n\n\nWickham, Hadley, Winston Chang, Lionel Henry, Thomas Lin Pedersen,\nKohske Takahashi, Claus Wilke, Kara Woo, Hiroaki Yutani, and Dewey\nDunnington. 2022. Ggplot2: Create Elegant Data Visualisations Using\nthe Grammar of Graphics. https://CRAN.R-project.org/package=ggplot2.\n\n\nWickham, Hadley, Romain François, Lionel Henry, Kirill Müller, and Davis\nVaughan. 2023. Dplyr: A Grammar of Data Manipulation. https://CRAN.R-project.org/package=dplyr.\n\n\nWickham, Hadley, Jim Hester, and Jennifer Bryan. 2022. Readr: Read\nRectangular Text Data. https://CRAN.R-project.org/package=readr."
  }
]